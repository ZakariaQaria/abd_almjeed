import streamlit as st
import cv2
import numpy as np
from PIL import Image
import io
import random

# Ø¥Ø¹Ø¯Ø§Ø¯ ØµÙØ­Ø© Streamlit
st.set_page_config(
    page_title="Ù…Ø®ØªØ¨Ø± Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…ØªÙ‚Ø¯Ù…",
    page_icon="ğŸ¨",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Ø¥Ø¶Ø§ÙØ© CSS Ù…Ø®ØµØµ Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªØµÙ…ÙŠÙ…
def inject_custom_css():
    st.markdown("""
    <style>
    :root {
        --primary: #2c3e50;
        --secondary: #8e44ad;
        --accent: #3498db;
        --dark-bg: #1e1e1e;
        --code-bg: #2d2d2d;
        --light: #ecf0f1;
        --success: #27ae60;
        --warning: #f39c12;
        --danger: #e74c3c;
    }

    .stApp {
        background: linear-gradient(135deg, #0f2027 0%, #203a43 50%, #2c5364 100%) !important;
        color: var(--light) !important;
        font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif !important;
    }

    .main .block-container {
        padding: 2rem 1rem !important;
        max-width: 1400px !important;
    }

    .custom-header {
        background: linear-gradient(to right, #2c3e50, #8e44ad) !important;
        color: white !important;
        padding: 1.5rem 2rem !important;
        text-align: center !important;
        border-bottom: 5px solid #3498db !important;
        margin: -2rem -1rem 2rem -1rem !important;
    }

    .section {
        background: rgba(45, 45, 45, 0.8) !important;
        border-radius: 15px !important;
        padding: 1.5rem !important;
        margin-bottom: 1.5rem !important;
        box-shadow: 0 8px 20px rgba(0, 0, 0, 0.4) !important;
        border: 1px solid rgba(255, 255, 255, 0.15) !important;
        backdrop-filter: blur(10px) !important;
    }

    h1, h2, h3 {
        color: #3498db !important;
        margin-bottom: 1rem !important;
    }

    .stButton>button {
        background: linear-gradient(to right, #3498db, #8e44ad) !important;
        color: white !important;
        border: none !important;
        padding: 12px 25px !important;
        border-radius: 50px !important;
        font-weight: bold !important;
        margin: 0.5rem 0 !important;
        transition: all 0.3s ease !important;
    }

    .stButton>button:hover {
        transform: translateY(-2px) !important;
        box-shadow: 0 5px 15px rgba(52, 152, 219, 0.4) !important;
    }

    .stSlider>div>div>div {
        background: #3498db !important;
    }

    .upload-section {
        border: 2px dashed #3498db !important;
        border-radius: 10px !important;
        padding: 2rem !important;
        text-align: center !important;
        margin: 1rem 0 !important;
        background: rgba(52, 152, 219, 0.1) !important;
        transition: all 0.3s ease !important;
    }

    .upload-section:hover {
        background: rgba(52, 152, 219, 0.2) !important;
    }

    .code-editor {
        background: #2d2d2d !important;
        border-radius: 10px !important;
        overflow: hidden !important;
        margin: 1.5rem 0 !important;
        box-shadow: 0 5px 15px rgba(0, 0, 0, 0.3) !important;
    }

    .editor-header {
        background: rgba(0, 0, 0, 0.4) !important;
        padding: 10px 15px !important;
        display: flex !important;
        align-items: center !important;
        gap: 10px !important;
        border-bottom: 1px solid rgba(255, 255, 255, 0.1) !important;
    }

    .editor-dot {
        width: 12px !important;
        height: 12px !important;
        border-radius: 50% !important;
    }

    .red { background: #ff5f56 !important; }
    .yellow { background: #ffbd2e !important; }
    .green { background: #27ca3f !important; }

    .editor-title {
        font-size: 0.9rem !important;
        color: #aaa !important;
        font-family: 'Courier New', monospace !important;
    }

    pre {
        background: #1e1e1e !important;
        padding: 1.5rem !important;
        border-radius: 0 0 10px 10px !important;
        margin: 0 !important;
    }

    code {
        color: #d4d4d4 !important;
        font-family: 'Courier New', monospace !important;
        font-size: 0.9rem !important;
    }

    .image-comparison {
        display: grid !important;
        grid-template-columns: 1fr 1fr !important;
        gap: 20px !important;
        margin: 2rem 0 !important;
    }

    .image-box {
        background: rgba(0, 0, 0, 0.3) !important;
        border-radius: 10px !important;
        padding: 15px !important;
        text-align: center !important;
        transition: all 0.3s ease !important;
    }

    .image-box:hover {
        transform: translateY(-5px) !important;
        box-shadow: 0 10px 25px rgba(0, 0, 0, 0.3) !important;
    }

    .image-label {
        display: block !important;
        margin-top: 10px !important;
        font-weight: bold !important;
        color: #3498db !important;
        font-size: 1.1rem !important;
    }

    .nav-buttons {
        display: flex !important;
        justify-content: center !important;
        gap: 15px !important;
        margin: 1.5rem 0 !important;
        flex-wrap: wrap !important;
    }

    .nav-btn {
        background: rgba(255, 255, 255, 0.15) !important;
        color: white !important;
        border: none !important;
        padding: 12px 20px !important;
        border-radius: 50px !important;
        cursor: pointer !important;
        transition: all 0.3s ease !important;
        font-family: 'Segoe UI', sans-serif !important;
        font-weight: bold !important;
        min-width: 120px !important;
        text-align: center !important;
    }

    .nav-btn:hover {
        background: rgba(52, 152, 219, 0.4) !important;
        transform: translateY(-3px) !important;
        box-shadow: 0 5px 15px rgba(52, 152, 219, 0.3) !important;
    }

    footer {
        text-align: center !important;
        padding: 2rem !important;
        background: rgba(0, 0, 0, 0.4) !important;
        color: #aaa !important;
        margin-top: 2rem !important;
        border-top: 1px solid rgba(255, 255, 255, 0.1) !important;
        border-radius: 0 0 15px 15px !important;
    }

    .stMarkdown {
        color: #ecf0f1 !important;
    }

    .stSlider label {
        color: #ecf0f1 !important;
        font-weight: bold !important;
    }

    .stAlert {
        background: rgba(231, 76, 60, 0.2) !important;
        border: 1px solid #e74c3c !important;
        border-radius: 10px !important;
    }

    .stTabs [data-baseweb="tab-list"] {
        gap: 8px !important;
        background-color: rgba(30, 30, 30, 0.7) !important;
        padding: 10px !important;
        border-radius: 15px !important;
    }

    .stTabs [data-baseweb="tab"] {
        height: 50px !important;
        white-space: pre !important;
        background-color: rgba(45, 45, 45, 0.8) !important;
        border-radius: 10px !important;
        gap: 10px !important;
        padding: 10px 20px !important;
        color: #ecf0f1 !important;
        font-weight: bold !important;
    }

    .stTabs [aria-selected="true"] {
        background-color: #3498db !important;
        color: white !important;
    }
    </style>
    """, unsafe_allow_html=True)

# Ø¯Ø§Ù„Ø© Ù„Ø¹Ø±Ø¶ Ù…Ø­Ø±Ø± Ø§Ù„Ø£ÙƒÙˆØ§Ø¯
def display_code_editor(code, language="python", filename="code.py"):
    st.markdown(f"""
    <div class="code-editor">
        <div class="editor-header">
            <div class="editor-dot red"></div>
            <div class="editor-dot yellow"></div>
            <div class="editor-dot green"></div>
            <div class="editor-title">{filename}</div>
        </div>
        
    </div>

    """, unsafe_allow_html=True)
    st.code(code,language=language)
# ==================== Ø¯ÙˆØ§Ù„ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ± ====================

def adjust_brightness_contrast(image, brightness=0, contrast=100):
    brightness = 0 if brightness is None else brightness
    contrast = 100 if contrast is None else contrast
    
    contrast = float(contrast + 100) / 100.0
    contrast = contrast ** 2
    
    adjusted_image = cv2.addWeighted(image, contrast, image, 0, brightness - 100)
    return adjusted_image

def convert_color_space(image, conversion_code):
    return cv2.cvtColor(image, conversion_code)

def apply_threshold(image, threshold_type, threshold_value=127):
    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
    if threshold_type == "THRESH_BINARY":
        _, result = cv2.threshold(gray, threshold_value, 255, cv2.THRESH_BINARY)
    elif threshold_type == "THRESH_BINARY_INV":
        _, result = cv2.threshold(gray, threshold_value, 255, cv2.THRESH_BINARY_INV)
    elif threshold_type == "THRESH_TRUNC":
        _, result = cv2.threshold(gray, threshold_value, 255, cv2.THRESH_TRUNC)
    elif threshold_type == "THRESH_TOZERO":
        _, result = cv2.threshold(gray, threshold_value, 255, cv2.THRESH_TOZERO)
    elif threshold_type == "THRESH_TOZERO_INV":
        _, result = cv2.threshold(gray, threshold_value, 255, cv2.THRESH_TOZERO_INV)
    elif threshold_type == "THRESH_OTSU":
        _, result = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    else:
        result = gray
    return cv2.cvtColor(result, cv2.COLOR_GRAY2RGB)

def apply_filter(image, filter_type, kernel_size=3):
    if filter_type == "Blur":
        return cv2.blur(image, (kernel_size, kernel_size))
    elif filter_type == "Gaussian Blur":
        return cv2.GaussianBlur(image, (kernel_size, kernel_size), 0)
    elif filter_type == "Median Blur":
        return cv2.medianBlur(image, kernel_size)
    elif filter_type == "Sharpen":
        kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])
        return cv2.filter2D(image, -1, kernel)
    elif filter_type == "Emboss":
        kernel = np.array([[-2,-1,0], [-1,1,1], [0,1,2]])
        return cv2.filter2D(image, -1, kernel)
    elif filter_type == "Edge Detection":
        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
        edges = cv2.Canny(gray, 100, 200)
        return cv2.cvtColor(edges, cv2.COLOR_GRAY2RGB)
    return image

def add_noise(image, noise_type):
    if noise_type == "Gaussian":
        row, col, ch = image.shape
        mean = 0
        var = 0.1
        sigma = var**0.5
        gauss = np.random.normal(mean, sigma, (row, col, ch))
        gauss = gauss.reshape(row, col, ch)
        noisy = image + gauss * 50
        return np.clip(noisy, 0, 255).astype(np.uint8)
    elif noise_type == "Salt & Pepper":
        row, col, ch = image.shape
        s_vs_p = 0.5
        amount = 0.04
        noisy = np.copy(image)
        # Salt mode
        num_salt = np.ceil(amount * image.size * s_vs_p)
        coords = [np.random.randint(0, i - 1, int(num_salt)) for i in image.shape]
        noisy[coords[0], coords[1], :] = 255
        # Pepper mode
        num_pepper = np.ceil(amount * image.size * (1. - s_vs_p))
        coords = [np.random.randint(0, i - 1, int(num_pepper)) for i in image.shape]
        noisy[coords[0], coords[1], :] = 0
        return noisy
    return image

def remove_noise(image, filter_type):
    if filter_type == "Median":
        return cv2.medianBlur(image, 5)
    elif filter_type == "Gaussian":
        return cv2.GaussianBlur(image, (5, 5), 0)
    elif filter_type == "Bilateral":
        return cv2.bilateralFilter(image, 9, 75, 75)
    return image

def detect_edges(image, method, threshold1=100, threshold2=200):
    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
    if method == "Canny":
        edges = cv2.Canny(gray, threshold1, threshold2)
    elif method == "Sobel":
        sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=5)
        sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=5)
        edges = np.sqrt(sobelx**2 + sobely**2)
        edges = np.uint8(edges / np.max(edges) * 255)
    elif method == "Laplacian":
        edges = cv2.Laplacian(gray, cv2.CV_64F)
        edges = np.uint8(np.absolute(edges))
    else:
        edges = gray
    return cv2.cvtColor(edges, cv2.COLOR_GRAY2RGB)

def apply_morphological_operation(image, operation, kernel_size=3):
    kernel = np.ones((kernel_size, kernel_size), np.uint8)
    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
    _, binary = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)
    
    if operation == "Erosion":
        result = cv2.erode(binary, kernel, iterations=1)
    elif operation == "Dilation":
        result = cv2.dilate(binary, kernel, iterations=1)
    elif operation == "Opening":
        result = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel)
    elif operation == "Closing":
        result = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)
    else:
        result = binary
        
    return cv2.cvtColor(result, cv2.COLOR_GRAY2RGB)

def apply_geometric_transform(image, transform, angle=0, scale=1.0):
    h, w = image.shape[:2]
    
    if transform == "Rotation":
        center = (w // 2, h // 2)
        matrix = cv2.getRotationMatrix2D(center, angle, scale)
        result = cv2.warpAffine(image, matrix, (w, h))
    elif transform == "Scaling":
        result = cv2.resize(image, None, fx=scale, fy=scale, interpolation=cv2.INTER_LINEAR)
    elif transform == "Translation":
        matrix = np.float32([[1, 0, 50], [0, 1, 50]])
        result = cv2.warpAffine(image, matrix, (w, h))
    elif transform == "Flipping":
        result = cv2.flip(image, 1)  # 0: vertical, 1: horizontal
    else:
        result = image
        
    return result

# ==================== Ø¯ÙˆØ§Ù„ Ø§Ù„Ù…Ø­Ø§Ø¶Ø±Ø§Øª ====================

def lecture_1():
    st.markdown("### ğŸ“š Ø§Ù„Ø´Ø±Ø­ Ø§Ù„Ù†Ø¸Ø±ÙŠ")
    st.markdown("""
    <p style='font-size: 1.1rem; line-height: 1.8;'>
    Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø±Ù‚Ù…ÙŠØ© Ù‡ÙŠ ØªÙ…Ø«ÙŠÙ„ Ø±Ù‚Ù…ÙŠ Ù„Ù„ØµÙˆØ±Ø© Ø§Ù„Ø·Ø¨ÙŠØ¹ÙŠØ© ØªØªÙƒÙˆÙ† Ù…Ù† Ù…ØµÙÙˆÙØ© Ù…Ù† Ø§Ù„Ø¨ÙƒØ³Ù„Ø§Øª. ÙƒÙ„ Ø¨ÙƒØ³Ù„ ÙŠØ­Ù…Ù„ Ù‚ÙŠÙ…Ø© Ø±Ù‚Ù…ÙŠØ© ØªÙ…Ø«Ù„ Ø´Ø¯Ø© Ø§Ù„Ø¥Ø¶Ø§Ø¡Ø© ÙˆØ§Ù„Ù„ÙˆÙ† ÙÙŠ ØªÙ„Ùƒ Ø§Ù„Ù†Ù‚Ø·Ø©. 
    ØªØ¹ØªÙ…Ø¯ Ø¬ÙˆØ¯Ø© Ø§Ù„ØµÙˆØ±Ø© Ø¹Ù„Ù‰ Ø«Ù„Ø§Ø«Ø© Ø¹ÙˆØ§Ù…Ù„ Ø±Ø¦ÙŠØ³ÙŠØ©: Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯ (Ø§Ù„Ø·ÙˆÙ„ ÙˆØ§Ù„Ø¹Ø±Ø¶)ØŒ Ø¹Ø¯Ø¯ Ø§Ù„Ù‚Ù†ÙˆØ§Øª Ø§Ù„Ù„ÙˆÙ†ÙŠØ©ØŒ ÙˆØ¹Ù…Ù‚ Ø§Ù„Ø¨Øª Ø§Ù„Ø°ÙŠ ÙŠØ­Ø¯Ø¯ Ø¹Ø¯Ø¯ Ø§Ù„Ø£Ù„ÙˆØ§Ù† Ø§Ù„Ù…Ø­ØªÙ…Ù„Ø© Ù„ÙƒÙ„ Ø¨ÙƒØ³Ù„.
    </p>
    """, unsafe_allow_html=True)
    
    code = '''
# ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© ÙˆØ¹Ø±Ø¶ Ù…Ø¹Ù„ÙˆÙ…Ø§ØªÙ‡Ø§
import cv2
import numpy as np

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©
image = cv2.imread('image.jpg')
image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

# Ø¹Ø±Ø¶ Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ØµÙˆØ±Ø©
print("Ø£Ø¨Ø¹Ø§Ø¯ Ø§Ù„ØµÙˆØ±Ø©:", image.shape)
print("Ø¹Ø¯Ø¯ Ø§Ù„Ù‚Ù†ÙˆØ§Øª:", image.shape[2] if len(image.shape) > 2 else 1)
print("Ù†ÙˆØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:", image.dtype)
print("Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø¯Ù†ÙŠØ§ ÙˆØ§Ù„Ø¹Ù„ÙŠØ§:", np.min(image), np.max(image))

# Ø­ÙØ¸ Ø§Ù„ØµÙˆØ±Ø©
cv2.imwrite('processed_image.jpg', image)
'''
    display_code_editor(code, filename="image_info.py")

def lecture_2():
    st.markdown("### ğŸ“š Ø§Ù„Ø´Ø±Ø­ Ø§Ù„Ù†Ø¸Ø±ÙŠ")
    st.markdown("""
    <p style='font-size: 1.1rem; line-height: 1.8;'>
    Ø£Ù†Ø¸Ù…Ø© Ø§Ù„Ø£Ù„ÙˆØ§Ù† Ø§Ù„Ù…Ø®ØªÙ„ÙØ© ØªØ³ØªØ®Ø¯Ù… Ù„Ø£ØºØ±Ø§Ø¶ Ù…ØªØ¹Ø¯Ø¯Ø© ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±. Ù†Ø¸Ø§Ù… RGB Ù‡Ùˆ Ø§Ù„Ù†Ø¸Ø§Ù… Ø§Ù„Ø£Ø³Ø§Ø³ÙŠ Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙÙŠ Ø§Ù„Ø¹Ø±Ø¶ØŒ 
    Ø¨ÙŠÙ†Ù…Ø§ Ù†Ø¸Ø§Ù… HSV Ù…ÙÙŠØ¯ Ù„ÙØµÙ„ Ø§Ù„Ø¥Ø¶Ø§Ø¡Ø© Ø¹Ù† Ø§Ù„Ù„ÙˆÙ†. Ù†Ø¸Ø§Ù… Grayscale ÙŠØ¨Ø³Ø· Ø§Ù„ØµÙˆØ±Ø© Ù„ØªØ­Ù„ÙŠÙ„ Ø§Ù„Ø´Ø¯Ø© ÙÙ‚Ø·.
    </p>
    """, unsafe_allow_html=True)
    
    code = '''
# Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ø¨ÙŠÙ† Ø£Ù†Ø¸Ù…Ø© Ø§Ù„Ø£Ù„ÙˆØ§Ù†
import cv2
import numpy as np

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©
image = cv2.imread('image.jpg')
image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

# Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Grayscale
gray = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2GRAY)

# Ø§Ù„ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ HSV
hsv = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2HSV)

# ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ù‚Ù†ÙˆØ§Øª ÙÙŠ Ù†Ø¸Ø§Ù… RGB
red_channel = image_rgb[:, :, 0]
green_channel = image_rgb[:, :, 1]
blue_channel = image_rgb[:, :, 2]

# ØªÙ‚Ø³ÙŠÙ… Ø§Ù„Ù‚Ù†ÙˆØ§Øª ÙÙŠ Ù†Ø¸Ø§Ù… HSV
hue_channel = hsv[:, :, 0]
saturation_channel = hsv[:, :, 1]
value_channel = hsv[:, :, 2]
'''
    display_code_editor(code, filename="color_spaces.py")

def lecture_3():
    st.markdown("### ğŸ“š Ø§Ù„Ø´Ø±Ø­ Ø§Ù„Ù†Ø¸Ø±ÙŠ")
    st.markdown("""
    <p style='font-size: 1.1rem; line-height: 1.8;'>
    ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø³Ø·ÙˆØ¹ ÙˆØ§Ù„ØªØ¨Ø§ÙŠÙ† Ù…Ù† Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±. ÙŠØªÙ… ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø³Ø·ÙˆØ¹ Ø¨Ø¥Ø¶Ø§ÙØ© Ù‚ÙŠÙ…Ø© Ø«Ø§Ø¨ØªØ© 
    Ø¥Ù„Ù‰ Ø¬Ù…ÙŠØ¹ ÙˆØ­Ø¯Ø§Øª Ø§Ù„Ø¨ÙƒØ³Ù„ ÙÙŠ Ø§Ù„ØµÙˆØ±Ø©ØŒ Ø¨ÙŠÙ†Ù…Ø§ ÙŠØªÙ… ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„ØªØ¨Ø§ÙŠÙ† Ø¨Ø¶Ø±Ø¨ Ù‚ÙŠÙ… Ø§Ù„Ø¨ÙƒØ³Ù„ ÙÙŠ Ù…Ø¹Ø§Ù…Ù„ Ø«Ø§Ø¨Øª. Ù‡Ø°Ù‡ 
    Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª ØªØ³Ø§Ø¹Ø¯ ÙÙŠ ØªØ­Ø³ÙŠÙ† Ø¬ÙˆØ¯Ø© Ø§Ù„ØµÙˆØ±Ø© ÙˆØ¥Ø¨Ø±Ø§Ø² Ø§Ù„ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ù…Ø®ÙÙŠØ©.
    </p>
    """, unsafe_allow_html=True)
    
    code = '''
# ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø³Ø·ÙˆØ¹ ÙˆØ§Ù„ØªØ¨Ø§ÙŠÙ† ÙˆØ§Ù„Ø¹ØªØ¨Ø©
import cv2
import numpy as np

def adjust_brightness_contrast(image, brightness=0, contrast=100):
    # Ø¶Ø¨Ø· Ø§Ù„Ù‚ÙŠÙ… Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ©
    brightness = 0 if brightness is None else brightness
    contrast = 100 if contrast is None else contrast
    
    # Ø­Ø³Ø§Ø¨ Ù…Ø¹Ø§Ù…Ù„ Ø§Ù„ØªØ¨Ø§ÙŠÙ†
    contrast_factor = float(contrast + 100) / 100.0
    contrast_factor = contrast_factor ** 2
    
    # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù…Ø¹Ø§Ø¯Ù„Ø©: output = input * contrast + brightness
    adjusted_image = cv2.addWeighted(
        image, contrast_factor, 
        image, 0, 
        brightness - 100
    )
    
    return adjusted_image

def apply_threshold(image, threshold_value=127):
    # ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ ØªØ¯Ø±Ø¬ Ø§Ù„Ø±Ù…Ø§Ø¯ÙŠ
    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
    
    # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø¹ØªØ¨Ø©
    _, thresholded = cv2.threshold(gray, threshold_value, 255, cv2.THRESH_BINARY)
    
    return cv2.cvtColor(thresholded, cv2.COLOR_GRAY2RGB)

def apply_negative(image):
    # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø³Ø§Ù„Ø¨Ø©
    return 255 - image

# Ø§Ø³ØªØ®Ø¯Ø§Ù… Ø§Ù„Ø¯ÙˆØ§Ù„
image = cv2.imread('image.jpg')
image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

# ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„Ø§Øª
bright_contrast = adjust_brightness_contrast(image_rgb, brightness=30, contrast=120)
thresholded = apply_threshold(image_rgb, threshold_value=150)
negative = apply_negative(image_rgb)
'''
    display_code_editor(code, filename="point_operations.py")

def lecture_4():
    st.markdown("### ğŸ“š Ø§Ù„Ø´Ø±Ø­ Ø§Ù„Ù†Ø¸Ø±ÙŠ")
    st.markdown("""
    <p style='font-size: 1.1rem; line-height: 1.8;'>
    Ø§Ù„Ù…Ø±Ø´Ø­Ø§Øª ÙˆØ§Ù„Ø§Ù„ØªÙØ§Ù Ù…Ù† Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ø£Ø³Ø§Ø³ÙŠØ© ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±. ØªØ¹ØªÙ…Ø¯ Ù‡Ø°Ù‡ Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø¹Ù„Ù‰ Ù†ÙˆØ§Ø© (Kernel) 
    ÙŠØªÙ… ØªØ·Ø¨ÙŠÙ‚Ù‡Ø§ Ø¹Ù„Ù‰ Ø§Ù„ØµÙˆØ±Ø© Ù„Ø¥Ø¬Ø±Ø§Ø¡ Ø¹Ù…Ù„ÙŠØ§Øª Ù…Ø«Ù„ Ø§Ù„ØªÙ†Ø¹ÙŠÙ…ØŒ Ø§Ù„Ø­Ø¯Ø©ØŒ Ø§Ù„ÙƒØ´Ù Ø¹Ù† Ø§Ù„Ø­ÙˆØ§ÙØŒ ÙˆØºÙŠØ±Ù‡Ø§ Ù…Ù† Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª.
    </p>
    """, unsafe_allow_html=True)
    
    code = '''
# ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù…Ø±Ø´Ø­Ø§Øª ÙˆØ§Ù„Ø§Ù„ØªÙØ§Ù
import cv2
import numpy as np

def apply_filter(image, filter_type, kernel_size=3):
    if filter_type == "Blur":
        return cv2.blur(image, (kernel_size, kernel_size))
    elif filter_type == "Gaussian Blur":
        return cv2.GaussianBlur(image, (kernel_size, kernel_size), 0)
    elif filter_type == "Median Blur":
        return cv2.medianBlur(image, kernel_size)
    elif filter_type == "Sharpen":
        kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])
        return cv2.filter2D(image, -1, kernel)
    elif filter_type == "Emboss":
        kernel = np.array([[-2,-1,0], [-1,1,1], [0,1,2]])
        return cv2.filter2D(image, -1, kernel)
    elif filter_type == "Edge Detection":
        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
        edges = cv2.Canny(gray, 100, 200)
        return cv2.cvtColor(edges, cv2.COLOR_GRAY2RGB)
    return image

# Ø¥Ù†Ø´Ø§Ø¡ Ù†ÙˆØ§Ø© Ù…Ø®ØµØµØ©
def create_custom_kernel():
    kernel = np.array([[0, -1, 0],
                       [-1, 5, -1],
                       [0, -1, 0]])
    return kernel

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© ÙˆØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù…Ø±Ø´Ø­Ø§Øª
image = cv2.imread('image.jpg')
image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

# ØªØ·Ø¨ÙŠÙ‚ Ù…Ø±Ø´Ø­Ø§Øª Ù…Ø®ØªÙ„ÙØ©
blurred = apply_filter(image_rgb, "Gaussian Blur", 5)
sharpened = apply_filter(image_rgb, "Sharpen")
edges = apply_filter(image_rgb, "Edge Detection")

# ØªØ·Ø¨ÙŠÙ‚ Ù†ÙˆØ§Ø© Ù…Ø®ØµØµØ©
custom_kernel = create_custom_kernel()
custom_filtered = cv2.filter2D(image_rgb, -1, custom_kernel)
'''
    display_code_editor(code, filename="filters.py")

def lecture_5():
    st.markdown("### ğŸ“š Ø§Ù„Ø´Ø±Ø­ Ø§Ù„Ù†Ø¸Ø±ÙŠ")
    st.markdown("""
    <p style='font-size: 1.1rem; line-height: 1.8;'>
    Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡ ÙÙŠ Ø§Ù„ØµÙˆØ± Ù‡ÙŠ ØªØ´ÙˆÙ‡Ø§Øª ØºÙŠØ± Ù…Ø±ØºÙˆØ¨ ÙÙŠÙ‡Ø§ ÙŠÙ…ÙƒÙ† Ø£Ù† ØªÙ†ØªØ¬ Ø¹Ù† Ø¸Ø±ÙˆÙ Ø§Ù„ØªØµÙˆÙŠØ± Ø§Ù„Ù…Ø®ØªÙ„ÙØ©. 
    ØªÙˆØ¬Ø¯ Ø£Ù†ÙˆØ§Ø¹ Ù…ØªØ¹Ø¯Ø¯Ø© Ù…Ù† Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡ Ù…Ø«Ù„ Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡ Ø§Ù„ØºÙˆØ³ÙŠØ© ÙˆØ¶ÙˆØ¶Ø§Ø¡ Ø§Ù„Ù…Ù„Ø­ ÙˆØ§Ù„ÙÙ„ÙÙ„. 
    ØªÙ‡Ø¯Ù Ø¹Ù…Ù„ÙŠØ§Øª Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡ Ø¥Ù„Ù‰ ØªØ­Ø³ÙŠÙ† Ø¬ÙˆØ¯Ø© Ø§Ù„ØµÙˆØ±Ø© Ù…Ø¹ Ø§Ù„Ø­ÙØ§Ø¸ Ø¹Ù„Ù‰ Ø§Ù„ØªÙØ§ØµÙŠÙ„ Ø§Ù„Ù…Ù‡Ù…Ø©.
    </p>
    """, unsafe_allow_html=True)
    
    code = '''
# Ø¥Ø¶Ø§ÙØ© ÙˆØ¥Ø²Ø§Ù„Ø© Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡
import cv2
import numpy as np

def add_noise(image, noise_type):
    if noise_type == "Gaussian":
        row, col, ch = image.shape
        mean = 0
        var = 0.1
        sigma = var**0.5
        gauss = np.random.normal(mean, sigma, (row, col, ch))
        gauss = gauss.reshape(row, col, ch)
        noisy = image + gauss * 50
        return np.clip(noisy, 0, 255).astype(np.uint8)
    elif noise_type == "Salt & Pepper":
        row, col, ch = image.shape
        s_vs_p = 0.5
        amount = 0.04
        noisy = np.copy(image)
        # Salt mode
        num_salt = np.ceil(amount * image.size * s_vs_p)
        coords = [np.random.randint(0, i - 1, int(num_salt)) for i in image.shape]
        noisy[coords[0], coords[1], :] = 255
        # Pepper mode
        num_pepper = np.ceil(amount * image.size * (1. - s_vs_p))
        coords = [np.random.randint(0, i - 1, int(num_pepper)) for i in image.shape]
        noisy[coords[0], coords[1], :] = 0
        return noisy
    return image

def remove_noise(image, filter_type):
    if filter_type == "Median":
        return cv2.medianBlur(image, 5)
    elif filter_type == "Gaussian":
        return cv2.GaussianBlur(image, (5, 5), 0)
    elif filter_type == "Bilateral":
        return cv2.bilateralFilter(image, 9, 75, 75)
    return image

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© ÙˆÙ…Ø¹Ø§Ù„Ø¬ØªÙ‡Ø§
image = cv2.imread('image.jpg')
image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

# Ø¥Ø¶Ø§ÙØ© Ø¶ÙˆØ¶Ø§Ø¡
noisy_image = add_noise(image_rgb, "Salt & Pepper")

# Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡
denoised_median = remove_noise(noisy_image, "Median")
denoised_bilateral = remove_noise(noisy_image, "Bilateral")
'''
    display_code_editor(code, filename="denoising.py")

def lecture_6():
    st.markdown("### ğŸ“š Ø§Ù„Ø´Ø±Ø­ Ø§Ù„Ù†Ø¸Ø±ÙŠ")
    st.markdown("""
    <p style='font-size: 1.1rem; line-height: 1.8;'>
    ÙƒØ´Ù Ø§Ù„Ø­ÙˆØ§Ù Ù‡Ùˆ Ø¹Ù…Ù„ÙŠØ© Ø£Ø³Ø§Ø³ÙŠØ© ÙÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ± ØªÙ‡Ø¯Ù Ø¥Ù„Ù‰ ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ù…Ù†Ø§Ø·Ù‚ Ø§Ù„ØªÙŠ ØªØªØºÙŠØ± ÙÙŠÙ‡Ø§ Ø´Ø¯Ø© 
    Ø§Ù„ØµÙˆØ±Ø© Ø¨Ø´ÙƒÙ„ Ù…ÙØ§Ø¬Ø¦. Ù‡Ø°Ù‡ Ø§Ù„Ø­ÙˆØ§Ù ØªÙ…Ø«Ù„ Ø¹Ø§Ø¯Ø© Ø­Ø¯ÙˆØ¯Ù‹Ø§ Ø¨ÙŠÙ† Ù…Ù†Ø§Ø·Ù‚ Ù…Ø®ØªÙ„ÙØ© ÙÙŠ Ø§Ù„ØµÙˆØ±Ø© ÙˆÙŠÙ…ÙƒÙ† 
    Ø§Ø³ØªØ®Ø¯Ø§Ù…Ù‡Ø§ ÙÙŠ ØªØ·Ø¨ÙŠÙ‚Ø§Øª Ù…Ø«Ù„ Ø§Ù„ØªØ¬Ø²Ø¦Ø© ÙˆØ§Ù„ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„Ø£Ø´ÙŠØ§Ø¡.
    </p>
    """, unsafe_allow_html=True)
    
    code = '''
# ÙƒØ´Ù Ø§Ù„Ø­ÙˆØ§Ù ÙÙŠ Ø§Ù„ØµÙˆØ±
import cv2
import numpy as np

def detect_edges(image, method, threshold1=100, threshold2=200):
    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
    
    if method == "Canny":
        edges = cv2.Canny(gray, threshold1, threshold2)
    elif method == "Sobel":
        sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=5)
        sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=5)
        edges = np.sqrt(sobelx**2 + sobely**2)
        edges = np.uint8(edges / np.max(edges) * 255)
    elif method == "Laplacian":
        edges = cv2.Laplacian(gray, cv2.CV_64F)
        edges = np.uint8(np.absolute(edges))
    elif method == "Prewitt":
        kernelx = np.array([[1,1,1],[0,0,0],[-1,-1,-1]])
        kernely = np.array([[-1,0,1],[-1,0,1],[-1,0,1]])
        prewittx = cv2.filter2D(gray, -1, kernelx)
        prewitty = cv2.filter2D(gray, -1, kernely)
        edges = np.sqrt(prewittx**2 + prewitty**2)
        edges = np.uint8(edges / np.max(edges) * 255)
    else:
        edges = gray
        
    return cv2.cvtColor(edges, cv2.COLOR_GRAY2RGB)

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©
image = cv2.imread('image.jpg')
image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

# ÙƒØ´Ù Ø§Ù„Ø­ÙˆØ§Ù Ø¨Ø·Ø±Ù‚ Ù…Ø®ØªÙ„ÙØ©
canny_edges = detect_edges(image_rgb, "Canny", 100, 200)
sobel_edges = detect_edges(image_rgb, "Sobel")
laplacian_edges = detect_edges(image_rgb, "Laplacian")

# ØªØ·Ø¨ÙŠÙ‚ Gaussian Blur Ù‚Ø¨Ù„ ÙƒØ´Ù Ø§Ù„Ø­ÙˆØ§Ù Ù„Ù„ØªÙ‚Ù„ÙŠÙ„ Ù…Ù† Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡
blurred = cv2.GaussianBlur(image_rgb, (5, 5), 0)
smoothed_edges = detect_edges(blurred, "Canny", 50, 150)
'''
    display_code_editor(code, filename="edge_detection.py")

def lecture_7():
    st.markdown("### ğŸ“š Ø§Ù„Ø´Ø±Ø­ Ø§Ù„Ù†Ø¸Ø±ÙŠ")
    st.markdown("""
    <p style='font-size: 1.1rem; line-height: 1.8;'>
    Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ù…ÙˆØ±ÙÙˆÙ„ÙˆØ¬ÙŠØ© Ù‡ÙŠ ØªÙ‚Ù†ÙŠØ§Øª Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ± Ø§Ù„Ø«Ù†Ø§Ø¦ÙŠØ© ØªØ¹ØªÙ…Ø¯ Ø¹Ù„Ù‰ Ø´ÙƒÙ„ ÙˆÙ‡ÙŠÙƒÙ„ Ø§Ù„Ø£Ø´ÙŠØ§Ø¡ ÙÙŠ Ø§Ù„ØµÙˆØ±Ø©. 
    Ù‡Ø°Ù‡ Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ù…ÙÙŠØ¯Ø© ÙÙŠ ØªÙ†Ø¸ÙŠÙ Ø§Ù„ØµÙˆØ± Ø§Ù„Ø«Ù†Ø§Ø¦ÙŠØ©ØŒ ÙˆØ¥Ø²Ø§Ù„Ø© Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡ØŒ ÙˆØ¹Ø²Ù„ Ø§Ù„Ø£Ø´ÙŠØ§Ø¡ØŒ ÙˆØªØ­Ø³ÙŠÙ† Ø§Ù„Ù…Ù„Ø§Ù…Ø­.
    </p>
    """, unsafe_allow_html=True)
    
    code = '''
# Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ù…ÙˆØ±ÙÙˆÙ„ÙˆØ¬ÙŠØ©
import cv2
import numpy as np

def apply_morphological_operation(image, operation, kernel_size=3, iterations=1):
    # ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø¥Ù„Ù‰ ØªØ¯Ø±Ø¬ Ø§Ù„Ø±Ù…Ø§Ø¯ÙŠ Ø«Ù… Ø¥Ù„Ù‰ Ø«Ù†Ø§Ø¦ÙŠØ©
    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
    _, binary = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)
    
    # Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ù†ÙˆØ§Ø©
    kernel = np.ones((kernel_size, kernel_size), np.uint8)
    
    # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ù…ÙˆØ±ÙÙˆÙ„ÙˆØ¬ÙŠØ©
    if operation == "Erosion":
        result = cv2.erode(binary, kernel, iterations=iterations)
    elif operation == "Dilation":
        result = cv2.dilate(binary, kernel, iterations=iterations)
    elif operation == "Opening":
        result = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel, iterations=iterations)
    elif operation == "Closing":
        result = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel, iterations=iterations)
    elif operation == "Gradient":
        result = cv2.morphologyEx(binary, cv2.MORPH_GRADIENT, kernel)
    elif operation == "Top Hat":
        result = cv2.morphologyEx(binary, cv2.MORPH_TOPHAT, kernel)
    elif operation == "Black Hat":
        result = cv2.morphologyEx(binary, cv2.MORPH_BLACKHAT, kernel)
    else:
        result = binary
        
    return cv2.cvtColor(result, cv2.COLOR_GRAY2RGB)

# Ø¥Ù†Ø´Ø§Ø¡ Ù†ÙˆØ§Ø© Ù…Ø®ØµØµØ©
def create_custom_kernel(shape="rect", size=3):
    if shape == "rect":
        return np.ones((size, size), np.uint8)
    elif shape == "ellipse":
        return cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (size, size))
    elif shape == "cross":
        return cv2.getStructuringElement(cv2.MORPH_CROSS, (size, size))
    else:
        return np.ones((size, size), np.uint8)

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©
image = cv2.imread('image.jpg')
image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

# ØªØ·Ø¨ÙŠÙ‚ Ø¹Ù…Ù„ÙŠØ§Øª Ù…ÙˆØ±ÙÙˆÙ„ÙˆØ¬ÙŠØ© Ù…Ø®ØªÙ„ÙØ©
eroded = apply_morphological_operation(image_rgb, "Erosion", 3, 1)
dilated = apply_morphological_operation(image_rgb, "Dilation", 3, 1)
opened = apply_morphological_operation(image_rgb, "Opening", 5, 1)
closed = apply_morphological_operation(image_rgb, "Closing", 5, 1)

# Ø§Ø³ØªØ®Ø¯Ø§Ù… Ù†ÙˆØ§Ø© Ù…Ø®ØµØµØ©
custom_kernel = create_custom_kernel("ellipse", 5)
custom_morph = cv2.morphologyEx(
    cv2.cvtColor(image_rgb, cv2.COLOR_RGB2GRAY), 
    cv2.MORPH_OPEN, 
    custom_kernel
)
custom_morph = cv2.cvtColor(custom_morph, cv2.COLOR_GRAY2RGB)
'''
    display_code_editor(code, filename="morphological.py")

def lecture_8():
    st.markdown("### ğŸ“š Ø§Ù„Ø´Ø±Ø­ Ø§Ù„Ù†Ø¸Ø±ÙŠ")
    st.markdown("""
    <p style='font-size: 1.1rem; line-height: 1.8;'>
    Ø§Ù„ØªØ­ÙˆÙŠÙ„Ø§Øª Ø§Ù„Ù‡Ù†Ø¯Ø³ÙŠØ© Ù‡ÙŠ Ø¹Ù…Ù„ÙŠØ§Øª ØªØºÙŠØ± Ø§Ù„Ù‡Ù†Ø¯Ø³Ø© Ø§Ù„Ù…ÙƒØ§Ù†ÙŠØ© Ù„Ù„ØµÙˆØ±Ø©. ØªØ´Ù…Ù„ Ù‡Ø°Ù‡ Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„ØªØ¯ÙˆÙŠØ±ØŒ Ø§Ù„Ù‚ÙŠØ§Ø³ØŒ 
    Ø§Ù„Ø§Ù†Ø¹ÙƒØ§Ø³ØŒ Ø§Ù„Ù‚ØµØŒ ÙˆØ§Ù„Ø§Ù†Ø²ÙŠØ§Ø­. Ù‡Ø°Ù‡ Ø§Ù„ØªØ­ÙˆÙŠÙ„Ø§Øª Ù…ÙÙŠØ¯Ø© ÙÙŠ ØªØµØ­ÙŠØ­ Ø§Ù„ØªØ´ÙˆÙ‡Ø§ØªØŒ ÙˆÙ…Ø·Ø§Ø¨Ù‚Ø© Ø§Ù„ØµÙˆØ±ØŒ ÙˆØªØ·Ø¨ÙŠÙ‚Ø§Øª Ø§Ù„Ø±Ø¤ÙŠØ© Ø§Ù„Ø­Ø§Ø³ÙˆØ¨ÙŠØ©.
    </p>
    """, unsafe_allow_html=True)
    
    code = '''
# Ø§Ù„ØªØ­ÙˆÙŠÙ„Ø§Øª Ø§Ù„Ù‡Ù†Ø¯Ø³ÙŠØ©
import cv2
import numpy as np

def apply_geometric_transform(image, transform, **kwargs):
    h, w = image.shape[:2]
    
    if transform == "Rotation":
        angle = kwargs.get('angle', 0)
        scale = kwargs.get('scale', 1.0)
        center = (w // 2, h // 2)
        matrix = cv2.getRotationMatrix2D(center, angle, scale)
        result = cv2.warpAffine(image, matrix, (w, h))
        
    elif transform == "Scaling":
        scale_x = kwargs.get('scale_x', 1.0)
        scale_y = kwargs.get('scale_y', 1.0)
        result = cv2.resize(image, None, fx=scale_x, fy=scale_y, 
                           interpolation=cv2.INTER_LINEAR)
        
    elif transform == "Translation":
        tx = kwargs.get('tx', 50)
        ty = kwargs.get('ty', 50)
        matrix = np.float32([[1, 0, tx], [0, 1, ty]])
        result = cv2.warpAffine(image, matrix, (w, h))
        
    elif transform == "Flipping":
        flip_code = kwargs.get('flip_code', 1)  # 0: vertical, 1: horizontal, -1: both
        result = cv2.flip(image, flip_code)
        
    elif transform == "Cropping":
        x = kwargs.get('x', 0)
        y = kwargs.get('y', 0)
        width = kwargs.get('width', w // 2)
        height = kwargs.get('height', h // 2)
        result = image[y:y+height, x:x+width]
        
    elif transform == "Affine":
        pts1 = np.float32([[50,50], [200,50], [50,200]])
        pts2 = np.float32([[10,100], [200,50], [100,250]])
        matrix = cv2.getAffineTransform(pts1, pts2)
        result = cv2.warpAffine(image, matrix, (w, h))
        
    elif transform == "Perspective":
        pts1 = np.float32([[56,65], [368,52], [28,387], [389,390]])
        pts2 = np.float32([[0,0], [300,0], [0,300], [300,300]])
        matrix = cv2.getPerspectiveTransform(pts1, pts2)
        result = cv2.warpPerspective(image, matrix, (300,300))
        
    else:
        result = image
        
    return result

# ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©
image = cv2.imread('image.jpg')
image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

# ØªØ·Ø¨ÙŠÙ‚ ØªØ­ÙˆÙŠÙ„Ø§Øª Ù‡Ù†Ø¯Ø³ÙŠØ© Ù…Ø®ØªÙ„ÙØ©
rotated = apply_geometric_transform(image_rgb, "Rotation", angle=45, scale=1.0)
scaled = apply_geometric_transform(image_rgb, "Scaling", scale_x=1.5, scale_y=1.5)
translated = apply_geometric_transform(image_rgb, "Translation", tx=100, ty=50)
flipped = apply_geometric_transform(image_rgb, "Flipping", flip_code=1)
cropped = apply_geometric_transform(image_rgb, "Cropping", x=100, y=100, width=200, height=200)

# ØªØ­ÙˆÙŠÙ„Ø§Øª Ù…ØªÙ‚Ø¯Ù…Ø©
affine = apply_geometric_transform(image_rgb, "Affine")
perspective = apply_geometric_transform(image_rgb, "Perspective")
'''
    display_code_editor(code, filename="geometric_transforms.py")

def main():
    # Ø­Ù‚Ù† CSS Ø§Ù„Ù…Ø®ØµØµ
    inject_custom_css()

    # Ø§Ù„Ø±Ø£Ø³ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
    st.markdown("""
    <div class="custom-header">
        <h1>ğŸ¨ Ù…Ø®ØªØ¨Ø± Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ± Ø§Ù„Ù…ØªÙ‚Ø¯Ù…</h1>
        <h3>Ù…Ø´Ø±ÙˆØ¹ Ù…Ø­Ø§Ø¶Ø±Ø§Øª Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ± Ø§Ù„Ø±Ù‚Ù…ÙŠØ©</h3>
    </div>
    """, unsafe_allow_html=True)

    # Ø¥Ù†Ø´Ø§Ø¡ Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù…Ø­Ø§Ø¶Ø±Ø§Øª
    lectures = [
        "Ø§Ù„Ù…Ø­Ø§Ø¶Ø±Ø© 1: Ù…Ø¯Ø®Ù„ ÙˆÙ…Ø¹Ø§ÙŠØ±Ø© Ø§Ù„ØµÙˆØ±",
        "Ø§Ù„Ù…Ø­Ø§Ø¶Ø±Ø© 2: Ø£Ù†Ø¸Ù…Ø© Ø§Ù„Ø£Ù„ÙˆØ§Ù†",
        "Ø§Ù„Ù…Ø­Ø§Ø¶Ø±Ø© 3: ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø³Ø·ÙˆØ¹ ÙˆØ§Ù„ØªØ¨Ø§ÙŠÙ†",
        "Ø§Ù„Ù…Ø­Ø§Ø¶Ø±Ø© 4: Ø§Ù„Ù…Ø±Ø´Ø­Ø§Øª ÙˆØ§Ù„Ø§Ù„ØªÙØ§Ù",
        "Ø§Ù„Ù…Ø­Ø§Ø¶Ø±Ø© 5: Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡",
        "Ø§Ù„Ù…Ø­Ø§Ø¶Ø±Ø© 6: ÙƒØ´Ù Ø§Ù„Ø­ÙˆØ§Ù",
        "Ø§Ù„Ù…Ø­Ø§Ø¶Ø±Ø© 7: Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ù…ÙˆØ±ÙÙˆÙ„ÙˆØ¬ÙŠØ©",
        "Ø§Ù„Ù…Ø­Ø§Ø¶Ø±Ø© 8: Ø§Ù„ØªØ­ÙˆÙŠÙ„Ø§Øª Ø§Ù„Ù‡Ù†Ø¯Ø³ÙŠØ©",
        "Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ"
    ]

    # Ø¥Ù†Ø´Ø§Ø¡ ØªØ¨ÙˆÙŠØ¨Ø§Øª Ù„Ù„Ù…Ø­Ø§Ø¶Ø±Ø§Øª
    tab1, tab2, tab3, tab4, tab5, tab6, tab7, tab8, tab9 = st.tabs(lectures)

    with tab1:
        st.markdown("## Ø§Ù„Ù…Ø­Ø§Ø¶Ø±Ø© 1: Ù…Ø¯Ø®Ù„ ÙˆÙ…Ø¹Ø§ÙŠØ±Ø© Ø§Ù„ØµÙˆØ± Ø§Ù„Ø±Ù‚Ù…ÙŠØ©")
        lecture_1()
        
        # Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø¹Ù…Ù„ÙŠ Ù„Ù„Ù…Ø­Ø§Ø¶Ø±Ø© 1
        st.markdown("### ğŸ§ª Ø§Ù„ØªØ¬Ø±Ø¨Ø© Ø§Ù„Ø¹Ù…Ù„ÙŠØ©")
        uploaded_file = st.file_uploader("Ø§Ø®ØªØ± ØµÙˆØ±Ø© Ù„Ù…Ø¹Ø§Ù„Ø¬ØªÙ‡Ø§", type=["jpg", "jpeg", "png"], key="lecture1")
        
        if uploaded_file is not None:
            file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
            image = cv2.imdecode(file_bytes, 1)
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            
            col1, col2 = st.columns(2)
            with col1:
                st.image(image, caption="ğŸ–¼ï¸ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©", use_container_width=True)
            
            with col2:
                st.info(f"**Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ØµÙˆØ±Ø©:**")
                st.write(f"**Ø§Ù„Ø£Ø¨Ø¹Ø§Ø¯:** {image.shape[1]} x {image.shape[0]}")
                st.write(f"**Ø¹Ø¯Ø¯ Ø§Ù„Ù‚Ù†ÙˆØ§Øª:** {image.shape[2]}")
                st.write(f"**Ù†ÙˆØ¹ Ø§Ù„Ø¨ÙŠØ§Ù†Ø§Øª:** {image.dtype}")
                st.write(f"**Ù…Ø¯Ù‰ Ø§Ù„Ù‚ÙŠÙ…:** {np.min(image)} Ø¥Ù„Ù‰ {np.max(image)}")

    with tab2:
        st.markdown("## Ø§Ù„Ù…Ø­Ø§Ø¶Ø±Ø© 2: Ø£Ù†Ø¸Ù…Ø© Ø§Ù„Ø£Ù„ÙˆØ§Ù† (Color Spaces)")
        lecture_2()
        
        # Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø¹Ù…Ù„ÙŠ Ù„Ù„Ù…Ø­Ø§Ø¶Ø±Ø© 2
        st.markdown("### ğŸ§ª Ø§Ù„ØªØ¬Ø±Ø¨Ø© Ø§Ù„Ø¹Ù…Ù„ÙŠØ©")
        uploaded_file = st.file_uploader("Ø§Ø®ØªØ± ØµÙˆØ±Ø© Ù„Ù…Ø¹Ø§Ù„Ø¬ØªÙ‡Ø§", type=["jpg", "jpeg", "png"], key="lecture2")
        
        if uploaded_file is not None:
            file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
            image = cv2.imdecode(file_bytes, 1)
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            
            color_space = st.selectbox("Ø§Ø®ØªØ± Ù†Ø¸Ø§Ù… Ø§Ù„Ø£Ù„ÙˆØ§Ù† Ù„Ù„ØªØ­ÙˆÙŠÙ„:", 
                                     ["RGB", "GRAY", "HSV", "LAB", "YUV"])
            
            if color_space == "GRAY":
                converted = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
                converted = cv2.cvtColor(converted, cv2.COLOR_GRAY2RGB)
            elif color_space == "HSV":
                converted = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)
            elif color_space == "LAB":
                converted = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)
            elif color_space == "YUV":
                converted = cv2.cvtColor(image, cv2.COLOR_RGB2YUV)
            else:
                converted = image
            
            col1, col2 = st.columns(2)
            with col1:
                st.image(image, caption="ğŸ–¼ï¸ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ© (RGB)", use_container_width=True)
            with col2:
                st.image(converted, caption=f"ğŸ”„ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø­ÙˆÙ„Ø© ({color_space})", use_container_width=True)

    with tab3:
        st.markdown("## Ø§Ù„Ù…Ø­Ø§Ø¶Ø±Ø© 3: ØªØ¹Ø¯ÙŠÙ„ Ø§Ù„Ø³Ø·ÙˆØ¹ ÙˆØ§Ù„ØªØ¨Ø§ÙŠÙ†")
        lecture_3()
        
        # Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø¹Ù…Ù„ÙŠ Ù„Ù„Ù…Ø­Ø§Ø¶Ø±Ø© 3
        st.markdown("### ğŸ§ª Ø§Ù„ØªØ¬Ø±Ø¨Ø© Ø§Ù„Ø¹Ù…Ù„ÙŠØ©")
        uploaded_file = st.file_uploader("Ø§Ø®ØªØ± ØµÙˆØ±Ø© Ù„Ù…Ø¹Ø§Ù„Ø¬ØªÙ‡Ø§", type=["jpg", "jpeg", "png"], key="lecture3")
        
        if uploaded_file is not None:
            file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
            image = cv2.imdecode(file_bytes, 1)
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            
            col1, col2 = st.columns(2)
            with col1:
                st.image(image, caption="ğŸ–¼ï¸ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©", use_container_width=True)
            
            with col2:
                brightness = st.slider("ğŸ”† Ø§Ù„Ø³Ø·ÙˆØ¹", -100, 100, 0, key="brightness_slider")
                contrast = st.slider("ğŸŒˆ Ø§Ù„ØªØ¨Ø§ÙŠÙ†", 0, 200, 100, key="contrast_slider")
                threshold = st.slider("âš«ï¸ Ø§Ù„Ø¹ØªØ¨Ø©", 0, 255, 127, key="threshold_slider")
                
                if st.button("ğŸš€ ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªØ¹Ø¯ÙŠÙ„Ø§Øª", key="apply_btn"):
                    adjusted = adjust_brightness_contrast(image, brightness, contrast)
                    thresholded = apply_threshold(image, "THRESH_BINARY", threshold)
                    negative = 255 - image
                    
                    tab_a, tab_b, tab_c = st.tabs(["Ø§Ù„Ø³Ø·ÙˆØ¹ ÙˆØ§Ù„ØªØ¨Ø§ÙŠÙ†", "Ø§Ù„Ø¹ØªØ¨Ø©", "Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø³Ø§Ù„Ø¨Ø©"])
                    
                    with tab_a:
                        st.image(adjusted, caption="ğŸ”„ Ø§Ù„Ø³Ø·ÙˆØ¹ ÙˆØ§Ù„ØªØ¨Ø§ÙŠÙ†", use_container_width=True)
                    with tab_b:
                        st.image(thresholded, caption="âš«ï¸ Ø§Ù„Ø¹ØªØ¨Ø©", use_container_width=True)
                    with tab_c:
                        st.image(negative, caption="ğŸŒ— Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø³Ø§Ù„Ø¨Ø©", use_container_width=True)

    with tab4:
        st.markdown("## Ø§Ù„Ù…Ø­Ø§Ø¶Ø±Ø© 4: Ø§Ù„Ù…Ø±Ø´Ø­Ø§Øª ÙˆØ§Ù„Ø§Ù„ØªÙØ§Ù")
        lecture_4()
        
        # Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø¹Ù…Ù„ÙŠ Ù„Ù„Ù…Ø­Ø§Ø¶Ø±Ø© 4
        st.markdown("### ğŸ§ª Ø§Ù„ØªØ¬Ø±Ø¨Ø© Ø§Ù„Ø¹Ù…Ù„ÙŠØ©")
        uploaded_file = st.file_uploader("Ø§Ø®ØªØ± ØµÙˆØ±Ø© Ù„Ù…Ø¹Ø§Ù„Ø¬ØªÙ‡Ø§", type=["jpg", "jpeg", "png"], key="lecture4")
        
        if uploaded_file is not None:
            file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
            image = cv2.imdecode(file_bytes, 1)
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            
            filter_type = st.selectbox("Ø§Ø®ØªØ± Ù†ÙˆØ¹ Ø§Ù„Ù…Ø±Ø´Ø­:", 
                                     ["Blur", "Gaussian Blur", "Median Blur", "Sharpen", "Emboss", "Edge Detection"])
            
            kernel_size = st.slider("Ø­Ø¬Ù… Ø§Ù„Ù†ÙˆØ§Ø©", 3, 15, 5, 2, key="kernel_size")
            
            if st.button("ğŸš€ ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù…Ø±Ø´Ø­", key="apply_filter_btn"):
                filtered = apply_filter(image, filter_type, kernel_size)
                
                col1, col2 = st.columns(2)
                with col1:
                    st.image(image, caption="ğŸ–¼ï¸ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©", use_container_width=True)
                with col2:
                    st.image(filtered, caption=f"âœ¨ Ø§Ù„ØµÙˆØ±Ø© Ø¨Ø¹Ø¯ {filter_type}", use_container_width=True)

    with tab5:
        st.markdown("## Ø§Ù„Ù…Ø­Ø§Ø¶Ø±Ø© 5: Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡")
        lecture_5()
        
        # Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø¹Ù…Ù„ÙŠ Ù„Ù„Ù…Ø­Ø§Ø¶Ø±Ø© 5
        st.markdown("### ğŸ§ª Ø§Ù„ØªØ¬Ø±Ø¨Ø© Ø§Ù„Ø¹Ù…Ù„ÙŠØ©")
        uploaded_file = st.file_uploader("Ø§Ø®ØªØ± ØµÙˆØ±Ø© Ù„Ù…Ø¹Ø§Ù„Ø¬ØªÙ‡Ø§", type=["jpg", "jpeg", "png"], key="lecture5")
        
        if uploaded_file is not None:
            file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
            image = cv2.imdecode(file_bytes, 1)
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            
            noise_type = st.selectbox("Ø§Ø®ØªØ± Ù†ÙˆØ¹ Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡:", ["Gaussian", "Salt & Pepper"])
            denoise_type = st.selectbox("Ø§Ø®ØªØ± Ø·Ø±ÙŠÙ‚Ø© Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡:", ["Median", "Gaussian", "Bilateral"])
            
            if st.button("ğŸš€ ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©", key="apply_denoise_btn"):
                # Ø¥Ø¶Ø§ÙØ© Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡
                noisy = add_noise(image, noise_type)
                
                # Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡
                denoised = remove_noise(noisy, denoise_type)
                
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.image(image, caption="ğŸ–¼ï¸ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©", use_container_width=True)
                with col2:
                    st.image(noisy, caption=f"ğŸ”Š Ø§Ù„ØµÙˆØ±Ø© Ù…Ø¹ {noise_type} noise", use_container_width=True)
                with col3:
                    st.image(denoised, caption=f"ğŸ”‡ Ø§Ù„ØµÙˆØ±Ø© Ø¨Ø¹Ø¯ {denoise_type} filter", use_container_width=True)

    with tab6:
        st.markdown("## Ø§Ù„Ù…Ø­Ø§Ø¶Ø±Ø© 6: ÙƒØ´Ù Ø§Ù„Ø­ÙˆØ§Ù")
        lecture_6()
        
        # Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø¹Ù…Ù„ÙŠ Ù„Ù„Ù…Ø­Ø§Ø¶Ø±Ø© 6
        st.markdown("### ğŸ§ª Ø§Ù„ØªØ¬Ø±Ø¨Ø© Ø§Ù„Ø¹Ù…Ù„ÙŠØ©")
        uploaded_file = st.file_uploader("Ø§Ø®ØªØ± ØµÙˆØ±Ø© Ù„Ù…Ø¹Ø§Ù„Ø¬ØªÙ‡Ø§", type=["jpg", "jpeg", "png"], key="lecture6")
        
        if uploaded_file is not None:
            file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
            image = cv2.imdecode(file_bytes, 1)
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            
            edge_method = st.selectbox("Ø§Ø®ØªØ± Ø·Ø±ÙŠÙ‚Ø© ÙƒØ´Ù Ø§Ù„Ø­ÙˆØ§Ù:", ["Canny", "Sobel", "Laplacian", "Prewitt"])
            
            if edge_method == "Canny":
                threshold1 = st.slider("Ø§Ù„Ø¹ØªØ¨Ø© Ø§Ù„Ø¯Ù†ÙŠØ§", 0, 255, 100, key="threshold1")
                threshold2 = st.slider("Ø§Ù„Ø¹ØªØ¨Ø© Ø§Ù„Ø¹Ù„ÙŠØ§", 0, 255, 200, key="threshold2")
            else:
                threshold1, threshold2 = 100, 200
            
            if st.button("ğŸš€ ÙƒØ´Ù Ø§Ù„Ø­ÙˆØ§Ù", key="detect_edges_btn"):
                edges = detect_edges(image, edge_method, threshold1, threshold2)
                
                col1, col2 = st.columns(2)
                with col1:
                    st.image(image, caption="ğŸ–¼ï¸ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©", use_container_width=True)
                with col2:
                    st.image(edges, caption=f"ğŸ” Ø§Ù„Ø­ÙˆØ§Ù Ø¨Ù€ {edge_method}", use_container_width=True)

    with tab7:
        st.markdown("## Ø§Ù„Ù…Ø­Ø§Ø¶Ø±Ø© 7: Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ù…ÙˆØ±ÙÙˆÙ„ÙˆØ¬ÙŠØ©")
        lecture_7()
        
        # Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø¹Ù…Ù„ÙŠ Ù„Ù„Ù…Ø­Ø§Ø¶Ø±Ø© 7
        st.markdown("### ğŸ§ª Ø§Ù„ØªØ¬Ø±Ø¨Ø© Ø§Ù„Ø¹Ù…Ù„ÙŠØ©")
        uploaded_file = st.file_uploader("Ø§Ø®ØªØ± ØµÙˆØ±Ø© Ù„Ù…Ø¹Ø§Ù„Ø¬ØªÙ‡Ø§", type=["jpg", "jpeg", "png"], key="lecture7")
        
        if uploaded_file is not None:
            file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
            image = cv2.imdecode(file_bytes, 1)
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            
            morph_operation = st.selectbox("Ø§Ø®ØªØ± Ø§Ù„Ø¹Ù…Ù„ÙŠØ© Ø§Ù„Ù…ÙˆØ±ÙÙˆÙ„ÙˆØ¬ÙŠØ©:", 
                                         ["Erosion", "Dilation", "Opening", "Closing", "Gradient"])
            
            kernel_size = st.slider("Ø­Ø¬Ù… Ø§Ù„Ù†ÙˆØ§Ø©", 3, 15, 5, 2, key="morph_kernel_size")
            iterations = st.slider("Ø¹Ø¯Ø¯ Ø§Ù„ØªÙƒØ±Ø§Ø±Ø§Øª", 1, 10, 1, key="morph_iterations")
            
            if st.button("ğŸš€ ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø¹Ù…Ù„ÙŠØ©", key="apply_morph_btn"):
                result = apply_morphological_operation(image, morph_operation, kernel_size, iterations)
                
                col1, col2 = st.columns(2)
                with col1:
                    st.image(image, caption="ğŸ–¼ï¸ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©", use_container_width=True)
                with col2:
                    st.image(result, caption=f"âœ¨ Ø¨Ø¹Ø¯ {morph_operation}", use_container_width=True)

    with tab8:
        st.markdown("## Ø§Ù„Ù…Ø­Ø§Ø¶Ø±Ø© 8: Ø§Ù„ØªØ­ÙˆÙŠÙ„Ø§Øª Ø§Ù„Ù‡Ù†Ø¯Ø³ÙŠØ©")
        lecture_8()
        
        # Ø§Ù„ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø¹Ù…Ù„ÙŠ Ù„Ù„Ù…Ø­Ø§Ø¶Ø±Ø© 8
        st.markdown("### ğŸ§ª Ø§Ù„ØªØ¬Ø±Ø¨Ø© Ø§Ù„Ø¹Ù…Ù„ÙŠØ©")
        uploaded_file = st.file_uploader("Ø§Ø®ØªØ± ØµÙˆØ±Ø© Ù„Ù…Ø¹Ø§Ù„Ø¬ØªÙ‡Ø§", type=["jpg", "jpeg", "png"], key="lecture8")
        
        if uploaded_file is not None:
            file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
            image = cv2.imdecode(file_bytes, 1)
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            
            transform_type = st.selectbox("Ø§Ø®ØªØ± Ù†ÙˆØ¹ Ø§Ù„ØªØ­ÙˆÙŠÙ„:", 
                                        ["Rotation", "Scaling", "Translation", "Flipping", "Cropping"])
            
            if transform_type == "Rotation":
                angle = st.slider("Ø²Ø§ÙˆÙŠØ© Ø§Ù„Ø¯ÙˆØ±Ø§Ù†", -180, 180, 45, key="rotation_angle")
                scale = st.slider("Ù…Ù‚ÙŠØ§Ø³ Ø§Ù„ØªÙƒØ¨ÙŠØ±", 0.1, 3.0, 1.0, 0.1, key="rotation_scale")
                result = apply_geometric_transform(image, transform_type, angle=angle, scale=scale)
                
            elif transform_type == "Scaling":
                scale_x = st.slider("Ù…Ù‚ÙŠØ§Ø³ Ø§Ù„ØªÙƒØ¨ÙŠØ± Ø§Ù„Ø£ÙÙ‚ÙŠ", 0.1, 3.0, 1.5, 0.1, key="scale_x")
                scale_y = st.slider("Ù…Ù‚ÙŠØ§Ø³ Ø§Ù„ØªÙƒØ¨ÙŠØ± Ø§Ù„Ø¹Ù…ÙˆØ¯ÙŠ", 0.1, 3.0, 1.5, 0.1, key="scale_y")
                result = apply_geometric_transform(image, transform_type, scale_x=scale_x, scale_y=scale_y)
                
            elif transform_type == "Translation":
                tx = st.slider("Ø§Ù„Ø¥Ø²Ø§Ø­Ø© Ø§Ù„Ø£ÙÙ‚ÙŠØ©", -200, 200, 100, key="translation_x")
                ty = st.slider("Ø§Ù„Ø¥Ø²Ø§Ø­Ø© Ø§Ù„Ø¹Ù…ÙˆØ¯ÙŠØ©", -200, 200, 50, key="translation_y")
                result = apply_geometric_transform(image, transform_type, tx=tx, ty=ty)
                
            elif transform_type == "Flipping":
                flip_code = st.selectbox("Ø§Ø®ØªØ± Ø§ØªØ¬Ø§Ù‡ Ø§Ù„Ø§Ù†Ø¹ÙƒØ§Ø³:", 
                                       [("Ø§ÙÙ‚ÙŠ", 1), ("Ø¹Ù…ÙˆØ¯ÙŠ", 0), ("ÙƒÙ„Ø§Ù‡Ù…Ø§", -1)], 
                                       format_func=lambda x: x[0])
                result = apply_geometric_transform(image, transform_type, flip_code=flip_code[1])
                
            elif transform_type == "Cropping":
                x = st.slider("Ø§Ù„Ù†Ù‚Ø·Ø© X", 0, image.shape[1]-100, 100, key="crop_x")
                y = st.slider("Ø§Ù„Ù†Ù‚Ø·Ø© Y", 0, image.shape[0]-100, 100, key="crop_y")
                width = st.slider("Ø§Ù„Ø¹Ø±Ø¶", 100, image.shape[1]-x, 200, key="crop_width")
                height = st.slider("Ø§Ù„Ø§Ø±ØªÙØ§Ø¹", 100, image.shape[0]-y, 200, key="crop_height")
                result = apply_geometric_transform(image, transform_type, x=x, y=y, width=width, height=height)
            
            if st.button("ğŸš€ ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„ØªØ­ÙˆÙŠÙ„", key="apply_transform_btn"):
                col1, col2 = st.columns(2)
                with col1:
                    st.image(image, caption="ğŸ–¼ï¸ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©", use_container_width=True)
                with col2:
                    st.image(result, caption=f"âœ¨ Ø¨Ø¹Ø¯ {transform_type}", use_container_width=True)

    with tab9:
        st.markdown("## Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠ: pipeline Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±")
        st.markdown("### ğŸ§ª Ø£Ù†Ø´Ø¦ pipeline Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ± Ø§Ù„Ø®Ø§Øµ Ø¨Ùƒ")
        
        uploaded_file = st.file_uploader("Ø§Ø®ØªØ± ØµÙˆØ±Ø© Ù„Ù…Ø¹Ø§Ù„Ø¬ØªÙ‡Ø§", type=["jpg", "jpeg", "png"], key="final_project")
        
        if uploaded_file is not None:
            file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
            image = cv2.imdecode(file_bytes, 1)
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            
            st.image(image, caption="ğŸ–¼ï¸ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©", use_container_width=True)
            
            # Ø¥Ø¹Ø¯Ø§Ø¯ pipeline Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
            st.markdown("### âš™ï¸ Ø®Ø·ÙˆØ§Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©:")
            steps = st.multiselect(
                "Ø§Ø®ØªØ± Ø®Ø·ÙˆØ§Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©:",
                ["ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ø±Ù…Ø§Ø¯ÙŠ", "Ø¶Ø¨Ø· Ø§Ù„Ø³Ø·ÙˆØ¹ ÙˆØ§Ù„ØªØ¨Ø§ÙŠÙ†", "ØªØ·Ø¨ÙŠÙ‚ Ù…Ø±Ø´Ø­", "ÙƒØ´Ù Ø§Ù„Ø­ÙˆØ§Ù", "Ø¹ØªØ¨Ø©", "Ø¹Ù…Ù„ÙŠØ§Øª Ù…ÙˆØ±ÙÙˆÙ„ÙˆØ¬ÙŠØ©"],
                default=["ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ø±Ù…Ø§Ø¯ÙŠ", "ÙƒØ´Ù Ø§Ù„Ø­ÙˆØ§Ù"]
            )
            
            processed_image = image.copy()
            process_history = []
            
            for step in steps:
                if step == "ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ Ø±Ù…Ø§Ø¯ÙŠ":
                    processed_image = cv2.cvtColor(processed_image, cv2.COLOR_RGB2GRAY)
                    processed_image = cv2.cvtColor(processed_image, cv2.COLOR_GRAY2RGB)
                    process_history.append("ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ ØªØ¯Ø±Ø¬ Ø§Ù„Ø±Ù…Ø§Ø¯ÙŠ")
                
                elif step == "Ø¶Ø¨Ø· Ø§Ù„Ø³Ø·ÙˆØ¹ ÙˆØ§Ù„ØªØ¨Ø§ÙŠÙ†":
                    processed_image = adjust_brightness_contrast(processed_image, 20, 120)
                    process_history.append("Ø¶Ø¨Ø· Ø§Ù„Ø³Ø·ÙˆØ¹ (+20) ÙˆØ§Ù„ØªØ¨Ø§ÙŠÙ† (+20%)")
                
                elif step == "ØªØ·Ø¨ÙŠÙ‚ Ù…Ø±Ø´Ø­":
                    processed_image = apply_filter(processed_image, "Gaussian Blur", 5)
                    process_history.append("ØªØ·Ø¨ÙŠÙ‚ Ù…Ø±Ø´Ø­ Gaussian Blur (5x5)")
                
                elif step == "ÙƒØ´Ù Ø§Ù„Ø­ÙˆØ§Ù":
                    processed_image = detect_edges(processed_image, "Canny", 100, 200)
                    process_history.append("ÙƒØ´Ù Ø§Ù„Ø­ÙˆØ§Ù Ø¨Ù€ Canny")
                
                elif step == "Ø¹ØªØ¨Ø©":
                    processed_image = apply_threshold(processed_image, "THRESH_BINARY", 127)
                    process_history.append("ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø¹ØªØ¨Ø© Ø§Ù„Ø«Ù†Ø§Ø¦ÙŠØ© (127)")
                
                elif step == "Ø¹Ù…Ù„ÙŠØ§Øª Ù…ÙˆØ±ÙÙˆÙ„ÙˆØ¬ÙŠØ©":
                    processed_image = apply_morphological_operation(processed_image, "Closing", 3)
                    process_history.append("Ø¹Ù…Ù„ÙŠØ© Closing Ù…ÙˆØ±ÙÙˆÙ„ÙˆØ¬ÙŠØ© (3x3)")
            
            if st.button("â–¶ï¸ ØªØ´ØºÙŠÙ„ Pipeline", key="run_pipeline"):
                st.markdown("### ğŸ“Š Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©:")
                
                col1, col2 = st.columns(2)
                with col1:
                    st.image(image, caption="ğŸ–¼ï¸ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©", use_container_width=True)
                with col2:
                    st.image(processed_image, caption="âœ¨ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©", use_container_width=True)
                
                st.markdown("### ğŸ“ Ø³Ø¬Ù„ Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©:")
                for i, step in enumerate(process_history, 1):
                    st.write(f"{i}. {step}")
                
                # Ø¥Ù…ÙƒØ§Ù†ÙŠØ© Ø­ÙØ¸ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù†Ø§ØªØ¬Ø©
                buf = io.BytesIO()
                processed_pil = Image.fromarray(processed_image)
                processed_pil.save(buf, format="JPEG", quality=95)
                byte_im = buf.getvalue()
                
                st.download_button(
                    label="ğŸ’¾ ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©",
                    data=byte_im,
                    file_name="processed_image.jpg",
                    mime="image/jpeg",
                    use_container_width=True
                )

    # Ø§Ù„ØªØ°ÙŠÙŠÙ„
    st.markdown("""
    <footer>
        <p>ØªÙ… Ø§Ù„ØªØµÙ…ÙŠÙ… ÙˆØ§Ù„ØªØ·ÙˆÙŠØ± Ø¨ÙˆØ§Ø³Ø·Ø© Ø§Ù„Ù…Ù‡Ù†Ø¯Ø³ Ø²ÙƒØ±ÙŠØ§ Ù‚Ø§Ø±ÙŠØ©</p>
        <p>Ù…Ø´Ø±ÙˆØ¹ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ± Ø§Ù„Ø±Ù‚Ù…ÙŠØ© - ÙƒÙ„ÙŠØ© Ø§Ù„Ù‡Ù†Ø¯Ø³Ø© Â© 2023</p>
    </footer>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()