import streamlit as st
import cv2
import numpy as np
from PIL import Image
import io
import random

# ÿ•ÿπÿØÿßÿØ ÿµŸÅÿ≠ÿ© Streamlit
st.set_page_config(
    page_title="ŸÖÿÆÿ™ÿ®ÿ± ŸÖÿπÿßŸÑÿ¨ÿ© ÿßŸÑÿµŸàÿ± ÿßŸÑŸÖÿ™ŸÇÿØŸÖ",
    page_icon="üé®",
    layout="wide",
    initial_sidebar_state="expanded"
)

# ÿ•ÿ∂ÿßŸÅÿ© CSS ŸÖÿÆÿµÿµ ŸÑÿ™ÿ∑ÿ®ŸäŸÇ ÿßŸÑÿ™ÿµŸÖŸäŸÖ
def inject_custom_css():
    st.markdown("""
    <style>
    :root {
        --primary: #2c3e50;
        --secondary: #8e44ad;
        --accent: #3498db;
        --dark-bg: #1e1e1e;
        --code-bg: #2d2d2d;
        --light: #ecf0f1;
        --success: #27ae60;
        --warning: #f39c12;
        --danger: #e74c3c;
    }

    .stApp {
        background: linear-gradient(135deg, #0f2027 0%, #203a43 50%, #2c5364 100%) !important;
        color: var(--light) !important;
        font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif !important;
    }

    .main .block-container {
        padding: 2rem 1rem !important;
        max-width: 1400px !important;
    }

    .custom-header {
        background: linear-gradient(to right, #2c3e50, #8e44ad) !important;
        color: white !important;
        padding: 1.5rem 2rem !important;
        text-align: center !important;
        border-bottom: 5px solid #3498db !important;
        margin: -2rem -1rem 2rem -1rem !important;
    }

    .section {
        background: rgba(45, 45, 45, 0.8) !important;
        border-radius: 15px !important;
        padding: 1.5rem !important;
        margin-bottom: 1.5rem !important;
        box-shadow: 0 8px 20px rgba(0, 0, 0, 0.4) !important;
        border: 1px solid rgba(255, 255, 255, 0.15) !important;
        backdrop-filter: blur(10px) !important;
    }

    h1, h2, h3 {
        color: #3498db !important;
        margin-bottom: 1rem !important;
    }

    .stButton>button {
        background: linear-gradient(to right, #3498db, #8e44ad) !important;
        color: white !important;
        border: none !important;
        padding: 12px 25px !important;
        border-radius: 50px !important;
        font-weight: bold !important;
        margin: 0.5rem 0 !important;
        transition: all 0.3s ease !important;
    }

    .stButton>button:hover {
        transform: translateY(-2px) !important;
        box-shadow: 0 5px 15px rgba(52, 152, 219, 0.4) !important;
    }

    .stSlider>div>div>div {
        background: #3498db !important;
    }

    .upload-section {
        border: 2px dashed #3498db !important;
        border-radius: 10px !important;
        padding: 2rem !important;
        text-align: center !important;
        margin: 1rem 0 !important;
        background: rgba(52, 152, 219, 0.1) !important;
        transition: all 0.3s ease !important;
    }

    .upload-section:hover {
        background: rgba(52, 152, 219, 0.2) !important;
    }

    .code-editor {
        background: #2d2d2d !important;
        border-radius: 10px !important;
        overflow: hidden !important;
        margin: 1.5rem 0 !important;
        box-shadow: 0 5px 15px rgba(0, 0, 0, 0.3) !important;
    }

    .editor-header {
        background: rgba(0, 0, 0, 0.4) !important;
        padding: 10px 15px !important;
        display: flex !important;
        align-items: center !important;
        gap: 10px !important;
        border-bottom: 1px solid rgba(255, 255, 255, 0.1) !important;
    }

    .editor-dot {
        width: 12px !important;
        height: 12px !important;
        border-radius: 50% !important;
    }

    .red { background: #ff5f56 !important; }
    .yellow { background: #ffbd2e !important; }
    .green { background: #27ca3f !important; }

    .editor-title {
        font-size: 0.9rem !important;
        color: #aaa !important;
        font-family: 'Courier New', monospace !important;
    }

    pre {
        background: #1e1e1e !important;
        padding: 1.5rem !important;
        border-radius: 0 0 10px 10px !important;
        margin: 0 !important;
    }

    code {
        color: #d4d4d4 !important;
        font-family: 'Courier New', monospace !important;
        font-size: 0.9rem !important;
    }

    .image-comparison {
        display: grid !important;
        grid-template-columns: 1fr 1fr !important;
        gap: 20px !important;
        margin: 2rem 0 !important;
    }

    .image-box {
        background: rgba(0, 0, 0, 0.3) !important;
        border-radius: 10px !important;
        padding: 15px !important;
        text-align: center !important;
        transition: all 0.3s ease !important;
    }

    .image-box:hover {
        transform: translateY(-5px) !important;
        box-shadow: 0 10px 25px rgba(0, 0, 0, 0.3) !important;
    }

    .image-label {
        display: block !important;
        margin-top: 10px !important;
        font-weight: bold !important;
        color: #3498db !important;
        font-size: 1.1rem !important;
    }

    .nav-buttons {
        display: flex !important;
        justify-content: center !important;
        gap: 15px !important;
        margin: 1.5rem 0 !important;
        flex-wrap: wrap !important;
    }

    .nav-btn {
        background: rgba(255, 255, 255, 0.15) !important;
        color: white !important;
        border: none !important;
        padding: 12px 20px !important;
        border-radius: 50px !important;
        cursor: pointer !important;
        transition: all 0.3s ease !important;
        font-family: 'Segoe UI', sans-serif !important;
        font-weight: bold !important;
        min-width: 120px !important;
        text-align: center !important;
    }

    .nav-btn:hover {
        background: rgba(52, 152, 219, 0.4) !important;
        transform: translateY(-3px) !important;
        box-shadow: 0 5px 15px rgba(52, 152, 219, 0.3) !important;
    }

    footer {
        text-align: center !important;
        padding: 2rem !important;
        background: rgba(0, 0, 0, 0.4) !important;
        color: #aaa !important;
        margin-top: 2rem !important;
        border-top: 1px solid rgba(255, 255, 255, 0.1) !important;
        border-radius: 0 0 15px 15px !important;
    }

    .stMarkdown {
        color: #ecf0f1 !important;
    }

    .stSlider label {
        color: #ecf0f1 !important;
        font-weight: bold !important;
    }

    .stAlert {
        background: rgba(231, 76, 60, 0.2) !important;
        border: 1px solid #e74c3c !important;
        border-radius: 10px !important;
    }

    .stTabs [data-baseweb="tab-list"] {
        gap: 8px !important;
        background-color: rgba(30, 30, 30, 0.7) !important;
        padding: 10px !important;
        border-radius: 15px !important;
    }

    .stTabs [data-baseweb="tab"] {
        height: 50px !important;
        white-space: pre !important;
        background-color: rgba(45, 45, 45, 0.8) !important;
        border-radius: 10px !important;
        gap: 10px !important;
        padding: 10px 20px !important;
        color: #ecf0f1 !important;
        font-weight: bold !important;
    }

    .stTabs [aria-selected="true"] {
        background-color: #3498db !important;
        color: white !important;
    }
    </style>
    """, unsafe_allow_html=True)

# ÿØÿßŸÑÿ© ŸÑÿπÿ±ÿ∂ ŸÖÿ≠ÿ±ÿ± ÿßŸÑÿ£ŸÉŸàÿßÿØ
def display_code_editor(code, language="python", filename="code.py"):
    st.markdown(f"""
    <div class="code-editor">
        <div class="editor-header">
            <div class="editor-dot red"></div>
            <div class="editor-dot yellow"></div>
            <div class="editor-dot green"></div>
            <div class="editor-title">{filename}</div>
        </div>
        
    </div>

    """, unsafe_allow_html=True)
    st.code(code,language=language)
# ==================== ÿØŸàÿßŸÑ ŸÖÿπÿßŸÑÿ¨ÿ© ÿßŸÑÿµŸàÿ± ====================

def adjust_brightness_contrast(image, brightness=0, contrast=100):
    brightness = 0 if brightness is None else brightness
    contrast = 100 if contrast is None else contrast
    
    contrast = float(contrast + 100) / 100.0
    contrast = contrast ** 2
    
    adjusted_image = cv2.addWeighted(image, contrast, image, 0, brightness - 100)
    return adjusted_image

def convert_color_space(image, conversion_code):
    return cv2.cvtColor(image, conversion_code)

def apply_threshold(image, threshold_type, threshold_value=127):
    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
    if threshold_type == "THRESH_BINARY":
        _, result = cv2.threshold(gray, threshold_value, 255, cv2.THRESH_BINARY)
    elif threshold_type == "THRESH_BINARY_INV":
        _, result = cv2.threshold(gray, threshold_value, 255, cv2.THRESH_BINARY_INV)
    elif threshold_type == "THRESH_TRUNC":
        _, result = cv2.threshold(gray, threshold_value, 255, cv2.THRESH_TRUNC)
    elif threshold_type == "THRESH_TOZERO":
        _, result = cv2.threshold(gray, threshold_value, 255, cv2.THRESH_TOZERO)
    elif threshold_type == "THRESH_TOZERO_INV":
        _, result = cv2.threshold(gray, threshold_value, 255, cv2.THRESH_TOZERO_INV)
    elif threshold_type == "THRESH_OTSU":
        _, result = cv2.threshold(gray, 0, 255, cv2.THRESH_BINARY + cv2.THRESH_OTSU)
    else:
        result = gray
    return cv2.cvtColor(result, cv2.COLOR_GRAY2RGB)

def apply_filter(image, filter_type, kernel_size=3):
    if filter_type == "Blur":
        return cv2.blur(image, (kernel_size, kernel_size))
    elif filter_type == "Gaussian Blur":
        return cv2.GaussianBlur(image, (kernel_size, kernel_size), 0)
    elif filter_type == "Median Blur":
        return cv2.medianBlur(image, kernel_size)
    elif filter_type == "Sharpen":
        kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])
        return cv2.filter2D(image, -1, kernel)
    elif filter_type == "Emboss":
        kernel = np.array([[-2,-1,0], [-1,1,1], [0,1,2]])
        return cv2.filter2D(image, -1, kernel)
    elif filter_type == "Edge Detection":
        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
        edges = cv2.Canny(gray, 100, 200)
        return cv2.cvtColor(edges, cv2.COLOR_GRAY2RGB)
    return image

def add_noise(image, noise_type):
    if noise_type == "Gaussian":
        row, col, ch = image.shape
        mean = 0
        var = 0.1
        sigma = var**0.5
        gauss = np.random.normal(mean, sigma, (row, col, ch))
        gauss = gauss.reshape(row, col, ch)
        noisy = image + gauss * 50
        return np.clip(noisy, 0, 255).astype(np.uint8)
    elif noise_type == "Salt & Pepper":
        row, col, ch = image.shape
        s_vs_p = 0.5
        amount = 0.04
        noisy = np.copy(image)
        # Salt mode
        num_salt = np.ceil(amount * image.size * s_vs_p)
        coords = [np.random.randint(0, i - 1, int(num_salt)) for i in image.shape]
        noisy[coords[0], coords[1], :] = 255
        # Pepper mode
        num_pepper = np.ceil(amount * image.size * (1. - s_vs_p))
        coords = [np.random.randint(0, i - 1, int(num_pepper)) for i in image.shape]
        noisy[coords[0], coords[1], :] = 0
        return noisy
    return image

def remove_noise(image, filter_type):
    if filter_type == "Median":
        return cv2.medianBlur(image, 5)
    elif filter_type == "Gaussian":
        return cv2.GaussianBlur(image, (5, 5), 0)
    elif filter_type == "Bilateral":
        return cv2.bilateralFilter(image, 9, 75, 75)
    return image

def detect_edges(image, method, threshold1=100, threshold2=200):
    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
    if method == "Canny":
        edges = cv2.Canny(gray, threshold1, threshold2)
    elif method == "Sobel":
        sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=5)
        sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=5)
        edges = np.sqrt(sobelx**2 + sobely**2)
        edges = np.uint8(edges / np.max(edges) * 255)
    elif method == "Laplacian":
        edges = cv2.Laplacian(gray, cv2.CV_64F)
        edges = np.uint8(np.absolute(edges))
    else:
        edges = gray
    return cv2.cvtColor(edges, cv2.COLOR_GRAY2RGB)

def apply_morphological_operation(image, operation, kernel_size=3):
    kernel = np.ones((kernel_size, kernel_size), np.uint8)
    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
    _, binary = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)
    
    if operation == "Erosion":
        result = cv2.erode(binary, kernel, iterations=1)
    elif operation == "Dilation":
        result = cv2.dilate(binary, kernel, iterations=1)
    elif operation == "Opening":
        result = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel)
    elif operation == "Closing":
        result = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel)
    else:
        result = binary
        
    return cv2.cvtColor(result, cv2.COLOR_GRAY2RGB)

def apply_geometric_transform(image, transform, angle=0, scale=1.0):
    h, w = image.shape[:2]
    
    if transform == "Rotation":
        center = (w // 2, h // 2)
        matrix = cv2.getRotationMatrix2D(center, angle, scale)
        result = cv2.warpAffine(image, matrix, (w, h))
    elif transform == "Scaling":
        result = cv2.resize(image, None, fx=scale, fy=scale, interpolation=cv2.INTER_LINEAR)
    elif transform == "Translation":
        matrix = np.float32([[1, 0, 50], [0, 1, 50]])
        result = cv2.warpAffine(image, matrix, (w, h))
    elif transform == "Flipping":
        result = cv2.flip(image, 1)  # 0: vertical, 1: horizontal
    else:
        result = image
        
    return result

# ==================== ÿØŸàÿßŸÑ ÿßŸÑŸÖÿ≠ÿßÿ∂ÿ±ÿßÿ™ ====================

def lecture_1():
    st.markdown("### üìö ÿßŸÑÿ¥ÿ±ÿ≠ ÿßŸÑŸÜÿ∏ÿ±Ÿä")
    st.markdown("""
    <p style='font-size: 1.1rem; line-height: 1.8;'>
    ÿßŸÑÿµŸàÿ±ÿ© ÿßŸÑÿ±ŸÇŸÖŸäÿ© ŸáŸä ÿ™ŸÖÿ´ŸäŸÑ ÿ±ŸÇŸÖŸä ŸÑŸÑÿµŸàÿ±ÿ© ÿßŸÑÿ∑ÿ®ŸäÿπŸäÿ© ÿ™ÿ™ŸÉŸàŸÜ ŸÖŸÜ ŸÖÿµŸÅŸàŸÅÿ© ŸÖŸÜ ÿßŸÑÿ®ŸÉÿ≥ŸÑÿßÿ™. ŸÉŸÑ ÿ®ŸÉÿ≥ŸÑ Ÿäÿ≠ŸÖŸÑ ŸÇŸäŸÖÿ© ÿ±ŸÇŸÖŸäÿ© ÿ™ŸÖÿ´ŸÑ ÿ¥ÿØÿ© ÿßŸÑÿ•ÿ∂ÿßÿ°ÿ© ŸàÿßŸÑŸÑŸàŸÜ ŸÅŸä ÿ™ŸÑŸÉ ÿßŸÑŸÜŸÇÿ∑ÿ©. 
    ÿ™ÿπÿ™ŸÖÿØ ÿ¨ŸàÿØÿ© ÿßŸÑÿµŸàÿ±ÿ© ÿπŸÑŸâ ÿ´ŸÑÿßÿ´ÿ© ÿπŸàÿßŸÖŸÑ ÿ±ÿ¶Ÿäÿ≥Ÿäÿ©: ÿßŸÑÿ£ÿ®ÿπÿßÿØ (ÿßŸÑÿ∑ŸàŸÑ ŸàÿßŸÑÿπÿ±ÿ∂)ÿå ÿπÿØÿØ ÿßŸÑŸÇŸÜŸàÿßÿ™ ÿßŸÑŸÑŸàŸÜŸäÿ©ÿå ŸàÿπŸÖŸÇ ÿßŸÑÿ®ÿ™ ÿßŸÑÿ∞Ÿä Ÿäÿ≠ÿØÿØ ÿπÿØÿØ ÿßŸÑÿ£ŸÑŸàÿßŸÜ ÿßŸÑŸÖÿ≠ÿ™ŸÖŸÑÿ© ŸÑŸÉŸÑ ÿ®ŸÉÿ≥ŸÑ.
    </p>
    """, unsafe_allow_html=True)
    
    code = '''
# ÿ™ÿ≠ŸÖŸäŸÑ ÿßŸÑÿµŸàÿ±ÿ© Ÿàÿπÿ±ÿ∂ ŸÖÿπŸÑŸàŸÖÿßÿ™Ÿáÿß
import cv2
import numpy as np

# ÿ™ÿ≠ŸÖŸäŸÑ ÿßŸÑÿµŸàÿ±ÿ©
image = cv2.imread('image.jpg')
image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

# ÿπÿ±ÿ∂ ŸÖÿπŸÑŸàŸÖÿßÿ™ ÿßŸÑÿµŸàÿ±ÿ©
print("ÿ£ÿ®ÿπÿßÿØ ÿßŸÑÿµŸàÿ±ÿ©:", image.shape)
print("ÿπÿØÿØ ÿßŸÑŸÇŸÜŸàÿßÿ™:", image.shape[2] if len(image.shape) > 2 else 1)
print("ŸÜŸàÿπ ÿßŸÑÿ®ŸäÿßŸÜÿßÿ™:", image.dtype)
print("ÿßŸÑŸÇŸäŸÖ ÿßŸÑÿØŸÜŸäÿß ŸàÿßŸÑÿπŸÑŸäÿß:", np.min(image), np.max(image))

# ÿ≠ŸÅÿ∏ ÿßŸÑÿµŸàÿ±ÿ©
cv2.imwrite('processed_image.jpg', image)
'''
    display_code_editor(code, filename="image_info.py")

def lecture_2():
    st.markdown("### üìö ÿßŸÑÿ¥ÿ±ÿ≠ ÿßŸÑŸÜÿ∏ÿ±Ÿä")
    st.markdown("""
    <p style='font-size: 1.1rem; line-height: 1.8;'>
    ÿ£ŸÜÿ∏ŸÖÿ© ÿßŸÑÿ£ŸÑŸàÿßŸÜ ÿßŸÑŸÖÿÆÿ™ŸÑŸÅÿ© ÿ™ÿ≥ÿ™ÿÆÿØŸÖ ŸÑÿ£ÿ∫ÿ±ÿßÿ∂ ŸÖÿ™ÿπÿØÿØÿ© ŸÅŸä ŸÖÿπÿßŸÑÿ¨ÿ© ÿßŸÑÿµŸàÿ±. ŸÜÿ∏ÿßŸÖ RGB ŸáŸà ÿßŸÑŸÜÿ∏ÿßŸÖ ÿßŸÑÿ£ÿ≥ÿßÿ≥Ÿä ÿßŸÑŸÖÿ≥ÿ™ÿÆÿØŸÖ ŸÅŸä ÿßŸÑÿπÿ±ÿ∂ÿå 
    ÿ®ŸäŸÜŸÖÿß ŸÜÿ∏ÿßŸÖ HSV ŸÖŸÅŸäÿØ ŸÑŸÅÿµŸÑ ÿßŸÑÿ•ÿ∂ÿßÿ°ÿ© ÿπŸÜ ÿßŸÑŸÑŸàŸÜ. ŸÜÿ∏ÿßŸÖ Grayscale Ÿäÿ®ÿ≥ÿ∑ ÿßŸÑÿµŸàÿ±ÿ© ŸÑÿ™ÿ≠ŸÑŸäŸÑ ÿßŸÑÿ¥ÿØÿ© ŸÅŸÇÿ∑.
    </p>
    """, unsafe_allow_html=True)
    
    code = '''
# ÿßŸÑÿ™ÿ≠ŸàŸäŸÑ ÿ®ŸäŸÜ ÿ£ŸÜÿ∏ŸÖÿ© ÿßŸÑÿ£ŸÑŸàÿßŸÜ
import cv2
import numpy as np

# ÿ™ÿ≠ŸÖŸäŸÑ ÿßŸÑÿµŸàÿ±ÿ©
image = cv2.imread('image.jpg')
image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

# ÿßŸÑÿ™ÿ≠ŸàŸäŸÑ ÿ•ŸÑŸâ Grayscale
gray = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2GRAY)

# ÿßŸÑÿ™ÿ≠ŸàŸäŸÑ ÿ•ŸÑŸâ HSV
hsv = cv2.cvtColor(image_rgb, cv2.COLOR_RGB2HSV)

# ÿ™ŸÇÿ≥ŸäŸÖ ÿßŸÑŸÇŸÜŸàÿßÿ™ ŸÅŸä ŸÜÿ∏ÿßŸÖ RGB
red_channel = image_rgb[:, :, 0]
green_channel = image_rgb[:, :, 1]
blue_channel = image_rgb[:, :, 2]

# ÿ™ŸÇÿ≥ŸäŸÖ ÿßŸÑŸÇŸÜŸàÿßÿ™ ŸÅŸä ŸÜÿ∏ÿßŸÖ HSV
hue_channel = hsv[:, :, 0]
saturation_channel = hsv[:, :, 1]
value_channel = hsv[:, :, 2]
'''
    display_code_editor(code, filename="color_spaces.py")

def lecture_3():
    st.markdown("### üìö ÿßŸÑÿ¥ÿ±ÿ≠ ÿßŸÑŸÜÿ∏ÿ±Ÿä")
    st.markdown("""
    <p style='font-size: 1.1rem; line-height: 1.8;'>
    ÿ™ÿπÿØŸäŸÑ ÿßŸÑÿ≥ÿ∑Ÿàÿπ ŸàÿßŸÑÿ™ÿ®ÿßŸäŸÜ ŸÖŸÜ ÿßŸÑÿπŸÖŸÑŸäÿßÿ™ ÿßŸÑÿ£ÿ≥ÿßÿ≥Ÿäÿ© ŸÅŸä ŸÖÿπÿßŸÑÿ¨ÿ© ÿßŸÑÿµŸàÿ±. Ÿäÿ™ŸÖ ÿ™ÿπÿØŸäŸÑ ÿßŸÑÿ≥ÿ∑Ÿàÿπ ÿ®ÿ•ÿ∂ÿßŸÅÿ© ŸÇŸäŸÖÿ© ÿ´ÿßÿ®ÿ™ÿ© 
    ÿ•ŸÑŸâ ÿ¨ŸÖŸäÿπ Ÿàÿ≠ÿØÿßÿ™ ÿßŸÑÿ®ŸÉÿ≥ŸÑ ŸÅŸä ÿßŸÑÿµŸàÿ±ÿ©ÿå ÿ®ŸäŸÜŸÖÿß Ÿäÿ™ŸÖ ÿ™ÿπÿØŸäŸÑ ÿßŸÑÿ™ÿ®ÿßŸäŸÜ ÿ®ÿ∂ÿ±ÿ® ŸÇŸäŸÖ ÿßŸÑÿ®ŸÉÿ≥ŸÑ ŸÅŸä ŸÖÿπÿßŸÖŸÑ ÿ´ÿßÿ®ÿ™. Ÿáÿ∞Ÿá 
    ÿßŸÑÿπŸÖŸÑŸäÿßÿ™ ÿ™ÿ≥ÿßÿπÿØ ŸÅŸä ÿ™ÿ≠ÿ≥ŸäŸÜ ÿ¨ŸàÿØÿ© ÿßŸÑÿµŸàÿ±ÿ© Ÿàÿ•ÿ®ÿ±ÿßÿ≤ ÿßŸÑÿ™ŸÅÿßÿµŸäŸÑ ÿßŸÑŸÖÿÆŸÅŸäÿ©.
    </p>
    """, unsafe_allow_html=True)
    
    code = '''
# ÿ™ÿπÿØŸäŸÑ ÿßŸÑÿ≥ÿ∑Ÿàÿπ ŸàÿßŸÑÿ™ÿ®ÿßŸäŸÜ ŸàÿßŸÑÿπÿ™ÿ®ÿ©
import cv2
import numpy as np

def adjust_brightness_contrast(image, brightness=0, contrast=100):
    # ÿ∂ÿ®ÿ∑ ÿßŸÑŸÇŸäŸÖ ÿßŸÑÿßŸÅÿ™ÿ±ÿßÿ∂Ÿäÿ©
    brightness = 0 if brightness is None else brightness
    contrast = 100 if contrast is None else contrast
    
    # ÿ≠ÿ≥ÿßÿ® ŸÖÿπÿßŸÖŸÑ ÿßŸÑÿ™ÿ®ÿßŸäŸÜ
    contrast_factor = float(contrast + 100) / 100.0
    contrast_factor = contrast_factor ** 2
    
    # ÿ™ÿ∑ÿ®ŸäŸÇ ÿßŸÑŸÖÿπÿßÿØŸÑÿ©: output = input * contrast + brightness
    adjusted_image = cv2.addWeighted(
        image, contrast_factor, 
        image, 0, 
        brightness - 100
    )
    
    return adjusted_image

def apply_threshold(image, threshold_value=127):
    # ÿ™ÿ≠ŸàŸäŸÑ ÿ•ŸÑŸâ ÿ™ÿØÿ±ÿ¨ ÿßŸÑÿ±ŸÖÿßÿØŸä
    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
    
    # ÿ™ÿ∑ÿ®ŸäŸÇ ÿßŸÑÿπÿ™ÿ®ÿ©
    _, thresholded = cv2.threshold(gray, threshold_value, 255, cv2.THRESH_BINARY)
    
    return cv2.cvtColor(thresholded, cv2.COLOR_GRAY2RGB)

def apply_negative(image):
    # ÿ™ÿ∑ÿ®ŸäŸÇ ÿßŸÑÿµŸàÿ±ÿ© ÿßŸÑÿ≥ÿßŸÑÿ®ÿ©
    return 255 - image

# ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ ÿßŸÑÿØŸàÿßŸÑ
image = cv2.imread('image.jpg')
image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

# ÿ™ÿ∑ÿ®ŸäŸÇ ÿßŸÑÿ™ÿπÿØŸäŸÑÿßÿ™
bright_contrast = adjust_brightness_contrast(image_rgb, brightness=30, contrast=120)
thresholded = apply_threshold(image_rgb, threshold_value=150)
negative = apply_negative(image_rgb)
'''
    display_code_editor(code, filename="point_operations.py")

def lecture_4():
    st.markdown("### üìö ÿßŸÑÿ¥ÿ±ÿ≠ ÿßŸÑŸÜÿ∏ÿ±Ÿä")
    st.markdown("""
    <p style='font-size: 1.1rem; line-height: 1.8;'>
    ÿßŸÑŸÖÿ±ÿ¥ÿ≠ÿßÿ™ ŸàÿßŸÑÿßŸÑÿ™ŸÅÿßŸÅ ŸÖŸÜ ÿßŸÑÿπŸÖŸÑŸäÿßÿ™ ÿßŸÑÿ£ÿ≥ÿßÿ≥Ÿäÿ© ŸÅŸä ŸÖÿπÿßŸÑÿ¨ÿ© ÿßŸÑÿµŸàÿ±. ÿ™ÿπÿ™ŸÖÿØ Ÿáÿ∞Ÿá ÿßŸÑÿπŸÖŸÑŸäÿßÿ™ ÿπŸÑŸâ ŸÜŸàÿßÿ© (Kernel) 
    Ÿäÿ™ŸÖ ÿ™ÿ∑ÿ®ŸäŸÇŸáÿß ÿπŸÑŸâ ÿßŸÑÿµŸàÿ±ÿ© ŸÑÿ•ÿ¨ÿ±ÿßÿ° ÿπŸÖŸÑŸäÿßÿ™ ŸÖÿ´ŸÑ ÿßŸÑÿ™ŸÜÿπŸäŸÖÿå ÿßŸÑÿ≠ÿØÿ©ÿå ÿßŸÑŸÉÿ¥ŸÅ ÿπŸÜ ÿßŸÑÿ≠ŸàÿßŸÅÿå Ÿàÿ∫Ÿäÿ±Ÿáÿß ŸÖŸÜ ÿßŸÑÿπŸÖŸÑŸäÿßÿ™.
    </p>
    """, unsafe_allow_html=True)
    
    code = '''
# ÿ™ÿ∑ÿ®ŸäŸÇ ÿßŸÑŸÖÿ±ÿ¥ÿ≠ÿßÿ™ ŸàÿßŸÑÿßŸÑÿ™ŸÅÿßŸÅ
import cv2
import numpy as np

def apply_filter(image, filter_type, kernel_size=3):
    if filter_type == "Blur":
        return cv2.blur(image, (kernel_size, kernel_size))
    elif filter_type == "Gaussian Blur":
        return cv2.GaussianBlur(image, (kernel_size, kernel_size), 0)
    elif filter_type == "Median Blur":
        return cv2.medianBlur(image, kernel_size)
    elif filter_type == "Sharpen":
        kernel = np.array([[-1,-1,-1], [-1,9,-1], [-1,-1,-1]])
        return cv2.filter2D(image, -1, kernel)
    elif filter_type == "Emboss":
        kernel = np.array([[-2,-1,0], [-1,1,1], [0,1,2]])
        return cv2.filter2D(image, -1, kernel)
    elif filter_type == "Edge Detection":
        gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
        edges = cv2.Canny(gray, 100, 200)
        return cv2.cvtColor(edges, cv2.COLOR_GRAY2RGB)
    return image

# ÿ•ŸÜÿ¥ÿßÿ° ŸÜŸàÿßÿ© ŸÖÿÆÿµÿµÿ©
def create_custom_kernel():
    kernel = np.array([[0, -1, 0],
                       [-1, 5, -1],
                       [0, -1, 0]])
    return kernel

# ÿ™ÿ≠ŸÖŸäŸÑ ÿßŸÑÿµŸàÿ±ÿ© Ÿàÿ™ÿ∑ÿ®ŸäŸÇ ÿßŸÑŸÖÿ±ÿ¥ÿ≠ÿßÿ™
image = cv2.imread('image.jpg')
image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

# ÿ™ÿ∑ÿ®ŸäŸÇ ŸÖÿ±ÿ¥ÿ≠ÿßÿ™ ŸÖÿÆÿ™ŸÑŸÅÿ©
blurred = apply_filter(image_rgb, "Gaussian Blur", 5)
sharpened = apply_filter(image_rgb, "Sharpen")
edges = apply_filter(image_rgb, "Edge Detection")

# ÿ™ÿ∑ÿ®ŸäŸÇ ŸÜŸàÿßÿ© ŸÖÿÆÿµÿµÿ©
custom_kernel = create_custom_kernel()
custom_filtered = cv2.filter2D(image_rgb, -1, custom_kernel)
'''
    display_code_editor(code, filename="filters.py")

def lecture_5():
    st.markdown("### üìö ÿßŸÑÿ¥ÿ±ÿ≠ ÿßŸÑŸÜÿ∏ÿ±Ÿä")
    st.markdown("""
    <p style='font-size: 1.1rem; line-height: 1.8;'>
    ÿßŸÑÿ∂Ÿàÿ∂ÿßÿ° ŸÅŸä ÿßŸÑÿµŸàÿ± ŸáŸä ÿ™ÿ¥ŸàŸáÿßÿ™ ÿ∫Ÿäÿ± ŸÖÿ±ÿ∫Ÿàÿ® ŸÅŸäŸáÿß ŸäŸÖŸÉŸÜ ÿ£ŸÜ ÿ™ŸÜÿ™ÿ¨ ÿπŸÜ ÿ∏ÿ±ŸàŸÅ ÿßŸÑÿ™ÿµŸàŸäÿ± ÿßŸÑŸÖÿÆÿ™ŸÑŸÅÿ©. 
    ÿ™Ÿàÿ¨ÿØ ÿ£ŸÜŸàÿßÿπ ŸÖÿ™ÿπÿØÿØÿ© ŸÖŸÜ ÿßŸÑÿ∂Ÿàÿ∂ÿßÿ° ŸÖÿ´ŸÑ ÿßŸÑÿ∂Ÿàÿ∂ÿßÿ° ÿßŸÑÿ∫Ÿàÿ≥Ÿäÿ© Ÿàÿ∂Ÿàÿ∂ÿßÿ° ÿßŸÑŸÖŸÑÿ≠ ŸàÿßŸÑŸÅŸÑŸÅŸÑ. 
    ÿ™ŸáÿØŸÅ ÿπŸÖŸÑŸäÿßÿ™ ÿ•ÿ≤ÿßŸÑÿ© ÿßŸÑÿ∂Ÿàÿ∂ÿßÿ° ÿ•ŸÑŸâ ÿ™ÿ≠ÿ≥ŸäŸÜ ÿ¨ŸàÿØÿ© ÿßŸÑÿµŸàÿ±ÿ© ŸÖÿπ ÿßŸÑÿ≠ŸÅÿßÿ∏ ÿπŸÑŸâ ÿßŸÑÿ™ŸÅÿßÿµŸäŸÑ ÿßŸÑŸÖŸáŸÖÿ©.
    </p>
    """, unsafe_allow_html=True)
    
    code = '''
# ÿ•ÿ∂ÿßŸÅÿ© Ÿàÿ•ÿ≤ÿßŸÑÿ© ÿßŸÑÿ∂Ÿàÿ∂ÿßÿ°
import cv2
import numpy as np

def add_noise(image, noise_type):
    if noise_type == "Gaussian":
        row, col, ch = image.shape
        mean = 0
        var = 0.1
        sigma = var**0.5
        gauss = np.random.normal(mean, sigma, (row, col, ch))
        gauss = gauss.reshape(row, col, ch)
        noisy = image + gauss * 50
        return np.clip(noisy, 0, 255).astype(np.uint8)
    elif noise_type == "Salt & Pepper":
        row, col, ch = image.shape
        s_vs_p = 0.5
        amount = 0.04
        noisy = np.copy(image)
        # Salt mode
        num_salt = np.ceil(amount * image.size * s_vs_p)
        coords = [np.random.randint(0, i - 1, int(num_salt)) for i in image.shape]
        noisy[coords[0], coords[1], :] = 255
        # Pepper mode
        num_pepper = np.ceil(amount * image.size * (1. - s_vs_p))
        coords = [np.random.randint(0, i - 1, int(num_pepper)) for i in image.shape]
        noisy[coords[0], coords[1], :] = 0
        return noisy
    return image

def remove_noise(image, filter_type):
    if filter_type == "Median":
        return cv2.medianBlur(image, 5)
    elif filter_type == "Gaussian":
        return cv2.GaussianBlur(image, (5, 5), 0)
    elif filter_type == "Bilateral":
        return cv2.bilateralFilter(image, 9, 75, 75)
    return image

# ÿ™ÿ≠ŸÖŸäŸÑ ÿßŸÑÿµŸàÿ±ÿ© ŸàŸÖÿπÿßŸÑÿ¨ÿ™Ÿáÿß
image = cv2.imread('image.jpg')
image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

# ÿ•ÿ∂ÿßŸÅÿ© ÿ∂Ÿàÿ∂ÿßÿ°
noisy_image = add_noise(image_rgb, "Salt & Pepper")

# ÿ•ÿ≤ÿßŸÑÿ© ÿßŸÑÿ∂Ÿàÿ∂ÿßÿ°
denoised_median = remove_noise(noisy_image, "Median")
denoised_bilateral = remove_noise(noisy_image, "Bilateral")
'''
    display_code_editor(code, filename="denoising.py")

def lecture_6():
    st.markdown("### üìö ÿßŸÑÿ¥ÿ±ÿ≠ ÿßŸÑŸÜÿ∏ÿ±Ÿä")
    st.markdown("""
    <p style='font-size: 1.1rem; line-height: 1.8;'>
    ŸÉÿ¥ŸÅ ÿßŸÑÿ≠ŸàÿßŸÅ ŸáŸà ÿπŸÖŸÑŸäÿ© ÿ£ÿ≥ÿßÿ≥Ÿäÿ© ŸÅŸä ŸÖÿπÿßŸÑÿ¨ÿ© ÿßŸÑÿµŸàÿ± ÿ™ŸáÿØŸÅ ÿ•ŸÑŸâ ÿ™ÿ≠ÿØŸäÿØ ÿßŸÑŸÖŸÜÿßÿ∑ŸÇ ÿßŸÑÿ™Ÿä ÿ™ÿ™ÿ∫Ÿäÿ± ŸÅŸäŸáÿß ÿ¥ÿØÿ© 
    ÿßŸÑÿµŸàÿ±ÿ© ÿ®ÿ¥ŸÉŸÑ ŸÖŸÅÿßÿ¨ÿ¶. Ÿáÿ∞Ÿá ÿßŸÑÿ≠ŸàÿßŸÅ ÿ™ŸÖÿ´ŸÑ ÿπÿßÿØÿ© ÿ≠ÿØŸàÿØŸãÿß ÿ®ŸäŸÜ ŸÖŸÜÿßÿ∑ŸÇ ŸÖÿÆÿ™ŸÑŸÅÿ© ŸÅŸä ÿßŸÑÿµŸàÿ±ÿ© ŸàŸäŸÖŸÉŸÜ 
    ÿßÿ≥ÿ™ÿÆÿØÿßŸÖŸáÿß ŸÅŸä ÿ™ÿ∑ÿ®ŸäŸÇÿßÿ™ ŸÖÿ´ŸÑ ÿßŸÑÿ™ÿ¨ÿ≤ÿ¶ÿ© ŸàÿßŸÑÿ™ÿπÿ±ŸÅ ÿπŸÑŸâ ÿßŸÑÿ£ÿ¥Ÿäÿßÿ°.
    </p>
    """, unsafe_allow_html=True)
    
    code = '''
# ŸÉÿ¥ŸÅ ÿßŸÑÿ≠ŸàÿßŸÅ ŸÅŸä ÿßŸÑÿµŸàÿ±
import cv2
import numpy as np

def detect_edges(image, method, threshold1=100, threshold2=200):
    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
    
    if method == "Canny":
        edges = cv2.Canny(gray, threshold1, threshold2)
    elif method == "Sobel":
        sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize=5)
        sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize=5)
        edges = np.sqrt(sobelx**2 + sobely**2)
        edges = np.uint8(edges / np.max(edges) * 255)
    elif method == "Laplacian":
        edges = cv2.Laplacian(gray, cv2.CV_64F)
        edges = np.uint8(np.absolute(edges))
    elif method == "Prewitt":
        kernelx = np.array([[1,1,1],[0,0,0],[-1,-1,-1]])
        kernely = np.array([[-1,0,1],[-1,0,1],[-1,0,1]])
        prewittx = cv2.filter2D(gray, -1, kernelx)
        prewitty = cv2.filter2D(gray, -1, kernely)
        edges = np.sqrt(prewittx**2 + prewitty**2)
        edges = np.uint8(edges / np.max(edges) * 255)
    else:
        edges = gray
        
    return cv2.cvtColor(edges, cv2.COLOR_GRAY2RGB)

# ÿ™ÿ≠ŸÖŸäŸÑ ÿßŸÑÿµŸàÿ±ÿ©
image = cv2.imread('image.jpg')
image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

# ŸÉÿ¥ŸÅ ÿßŸÑÿ≠ŸàÿßŸÅ ÿ®ÿ∑ÿ±ŸÇ ŸÖÿÆÿ™ŸÑŸÅÿ©
canny_edges = detect_edges(image_rgb, "Canny", 100, 200)
sobel_edges = detect_edges(image_rgb, "Sobel")
laplacian_edges = detect_edges(image_rgb, "Laplacian")

# ÿ™ÿ∑ÿ®ŸäŸÇ Gaussian Blur ŸÇÿ®ŸÑ ŸÉÿ¥ŸÅ ÿßŸÑÿ≠ŸàÿßŸÅ ŸÑŸÑÿ™ŸÇŸÑŸäŸÑ ŸÖŸÜ ÿßŸÑÿ∂Ÿàÿ∂ÿßÿ°
blurred = cv2.GaussianBlur(image_rgb, (5, 5), 0)
smoothed_edges = detect_edges(blurred, "Canny", 50, 150)
'''
    display_code_editor(code, filename="edge_detection.py")

def lecture_7():
    st.markdown("### üìö ÿßŸÑÿ¥ÿ±ÿ≠ ÿßŸÑŸÜÿ∏ÿ±Ÿä")
    st.markdown("""
    <p style='font-size: 1.1rem; line-height: 1.8;'>
    ÿßŸÑÿπŸÖŸÑŸäÿßÿ™ ÿßŸÑŸÖŸàÿ±ŸÅŸàŸÑŸàÿ¨Ÿäÿ© ŸáŸä ÿ™ŸÇŸÜŸäÿßÿ™ ŸÑŸÖÿπÿßŸÑÿ¨ÿ© ÿßŸÑÿµŸàÿ± ÿßŸÑÿ´ŸÜÿßÿ¶Ÿäÿ© ÿ™ÿπÿ™ŸÖÿØ ÿπŸÑŸâ ÿ¥ŸÉŸÑ ŸàŸáŸäŸÉŸÑ ÿßŸÑÿ£ÿ¥Ÿäÿßÿ° ŸÅŸä ÿßŸÑÿµŸàÿ±ÿ©. 
    Ÿáÿ∞Ÿá ÿßŸÑÿπŸÖŸÑŸäÿßÿ™ ŸÖŸÅŸäÿØÿ© ŸÅŸä ÿ™ŸÜÿ∏ŸäŸÅ ÿßŸÑÿµŸàÿ± ÿßŸÑÿ´ŸÜÿßÿ¶Ÿäÿ©ÿå Ÿàÿ•ÿ≤ÿßŸÑÿ© ÿßŸÑÿ∂Ÿàÿ∂ÿßÿ°ÿå Ÿàÿπÿ≤ŸÑ ÿßŸÑÿ£ÿ¥Ÿäÿßÿ°ÿå Ÿàÿ™ÿ≠ÿ≥ŸäŸÜ ÿßŸÑŸÖŸÑÿßŸÖÿ≠.
    </p>
    """, unsafe_allow_html=True)
    
    code = '''
# ÿßŸÑÿπŸÖŸÑŸäÿßÿ™ ÿßŸÑŸÖŸàÿ±ŸÅŸàŸÑŸàÿ¨Ÿäÿ©
import cv2
import numpy as np

def apply_morphological_operation(image, operation, kernel_size=3, iterations=1):
    # ÿ™ÿ≠ŸàŸäŸÑ ÿßŸÑÿµŸàÿ±ÿ© ÿ•ŸÑŸâ ÿ™ÿØÿ±ÿ¨ ÿßŸÑÿ±ŸÖÿßÿØŸä ÿ´ŸÖ ÿ•ŸÑŸâ ÿ´ŸÜÿßÿ¶Ÿäÿ©
    gray = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
    _, binary = cv2.threshold(gray, 127, 255, cv2.THRESH_BINARY)
    
    # ÿ•ŸÜÿ¥ÿßÿ° ÿßŸÑŸÜŸàÿßÿ©
    kernel = np.ones((kernel_size, kernel_size), np.uint8)
    
    # ÿ™ÿ∑ÿ®ŸäŸÇ ÿßŸÑÿπŸÖŸÑŸäÿ© ÿßŸÑŸÖŸàÿ±ŸÅŸàŸÑŸàÿ¨Ÿäÿ©
    if operation == "Erosion":
        result = cv2.erode(binary, kernel, iterations=iterations)
    elif operation == "Dilation":
        result = cv2.dilate(binary, kernel, iterations=iterations)
    elif operation == "Opening":
        result = cv2.morphologyEx(binary, cv2.MORPH_OPEN, kernel, iterations=iterations)
    elif operation == "Closing":
        result = cv2.morphologyEx(binary, cv2.MORPH_CLOSE, kernel, iterations=iterations)
    elif operation == "Gradient":
        result = cv2.morphologyEx(binary, cv2.MORPH_GRADIENT, kernel)
    elif operation == "Top Hat":
        result = cv2.morphologyEx(binary, cv2.MORPH_TOPHAT, kernel)
    elif operation == "Black Hat":
        result = cv2.morphologyEx(binary, cv2.MORPH_BLACKHAT, kernel)
    else:
        result = binary
        
    return cv2.cvtColor(result, cv2.COLOR_GRAY2RGB)

# ÿ•ŸÜÿ¥ÿßÿ° ŸÜŸàÿßÿ© ŸÖÿÆÿµÿµÿ©
def create_custom_kernel(shape="rect", size=3):
    if shape == "rect":
        return np.ones((size, size), np.uint8)
    elif shape == "ellipse":
        return cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (size, size))
    elif shape == "cross":
        return cv2.getStructuringElement(cv2.MORPH_CROSS, (size, size))
    else:
        return np.ones((size, size), np.uint8)

# ÿ™ÿ≠ŸÖŸäŸÑ ÿßŸÑÿµŸàÿ±ÿ©
image = cv2.imread('image.jpg')
image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

# ÿ™ÿ∑ÿ®ŸäŸÇ ÿπŸÖŸÑŸäÿßÿ™ ŸÖŸàÿ±ŸÅŸàŸÑŸàÿ¨Ÿäÿ© ŸÖÿÆÿ™ŸÑŸÅÿ©
eroded = apply_morphological_operation(image_rgb, "Erosion", 3, 1)
dilated = apply_morphological_operation(image_rgb, "Dilation", 3, 1)
opened = apply_morphological_operation(image_rgb, "Opening", 5, 1)
closed = apply_morphological_operation(image_rgb, "Closing", 5, 1)

# ÿßÿ≥ÿ™ÿÆÿØÿßŸÖ ŸÜŸàÿßÿ© ŸÖÿÆÿµÿµÿ©
custom_kernel = create_custom_kernel("ellipse", 5)
custom_morph = cv2.morphologyEx(
    cv2.cvtColor(image_rgb, cv2.COLOR_RGB2GRAY), 
    cv2.MORPH_OPEN, 
    custom_kernel
)
custom_morph = cv2.cvtColor(custom_morph, cv2.COLOR_GRAY2RGB)
'''
    display_code_editor(code, filename="morphological.py")

def lecture_8():
    st.markdown("### üìö ÿßŸÑÿ¥ÿ±ÿ≠ ÿßŸÑŸÜÿ∏ÿ±Ÿä")
    st.markdown("""
    <p style='font-size: 1.1rem; line-height: 1.8;'>
    ÿßŸÑÿ™ÿ≠ŸàŸäŸÑÿßÿ™ ÿßŸÑŸáŸÜÿØÿ≥Ÿäÿ© ŸáŸä ÿπŸÖŸÑŸäÿßÿ™ ÿ™ÿ∫Ÿäÿ± ÿßŸÑŸáŸÜÿØÿ≥ÿ© ÿßŸÑŸÖŸÉÿßŸÜŸäÿ© ŸÑŸÑÿµŸàÿ±ÿ©. ÿ™ÿ¥ŸÖŸÑ Ÿáÿ∞Ÿá ÿßŸÑÿπŸÖŸÑŸäÿßÿ™ ÿßŸÑÿ™ÿØŸàŸäÿ±ÿå ÿßŸÑŸÇŸäÿßÿ≥ÿå 
    ÿßŸÑÿßŸÜÿπŸÉÿßÿ≥ÿå ÿßŸÑŸÇÿµÿå ŸàÿßŸÑÿßŸÜÿ≤Ÿäÿßÿ≠. Ÿáÿ∞Ÿá ÿßŸÑÿ™ÿ≠ŸàŸäŸÑÿßÿ™ ŸÖŸÅŸäÿØÿ© ŸÅŸä ÿ™ÿµÿ≠Ÿäÿ≠ ÿßŸÑÿ™ÿ¥ŸàŸáÿßÿ™ÿå ŸàŸÖÿ∑ÿßÿ®ŸÇÿ© ÿßŸÑÿµŸàÿ±ÿå Ÿàÿ™ÿ∑ÿ®ŸäŸÇÿßÿ™ ÿßŸÑÿ±ÿ§Ÿäÿ© ÿßŸÑÿ≠ÿßÿ≥Ÿàÿ®Ÿäÿ©.
    </p>
    """, unsafe_allow_html=True)
    
    code = '''
# ÿßŸÑÿ™ÿ≠ŸàŸäŸÑÿßÿ™ ÿßŸÑŸáŸÜÿØÿ≥Ÿäÿ©
import cv2
import numpy as np

def apply_geometric_transform(image, transform, **kwargs):
    h, w = image.shape[:2]
    
    if transform == "Rotation":
        angle = kwargs.get('angle', 0)
        scale = kwargs.get('scale', 1.0)
        center = (w // 2, h // 2)
        matrix = cv2.getRotationMatrix2D(center, angle, scale)
        result = cv2.warpAffine(image, matrix, (w, h))
        
    elif transform == "Scaling":
        scale_x = kwargs.get('scale_x', 1.0)
        scale_y = kwargs.get('scale_y', 1.0)
        result = cv2.resize(image, None, fx=scale_x, fy=scale_y, 
                           interpolation=cv2.INTER_LINEAR)
        
    elif transform == "Translation":
        tx = kwargs.get('tx', 50)
        ty = kwargs.get('ty', 50)
        matrix = np.float32([[1, 0, tx], [0, 1, ty]])
        result = cv2.warpAffine(image, matrix, (w, h))
        
    elif transform == "Flipping":
        flip_code = kwargs.get('flip_code', 1)  # 0: vertical, 1: horizontal, -1: both
        result = cv2.flip(image, flip_code)
        
    elif transform == "Cropping":
        x = kwargs.get('x', 0)
        y = kwargs.get('y', 0)
        width = kwargs.get('width', w // 2)
        height = kwargs.get('height', h // 2)
        result = image[y:y+height, x:x+width]
        
    elif transform == "Affine":
        pts1 = np.float32([[50,50], [200,50], [50,200]])
        pts2 = np.float32([[10,100], [200,50], [100,250]])
        matrix = cv2.getAffineTransform(pts1, pts2)
        result = cv2.warpAffine(image, matrix, (w, h))
        
    elif transform == "Perspective":
        pts1 = np.float32([[56,65], [368,52], [28,387], [389,390]])
        pts2 = np.float32([[0,0], [300,0], [0,300], [300,300]])
        matrix = cv2.getPerspectiveTransform(pts1, pts2)
        result = cv2.warpPerspective(image, matrix, (300,300))
        
    else:
        result = image
        
    return result

# ÿ™ÿ≠ŸÖŸäŸÑ ÿßŸÑÿµŸàÿ±ÿ©
image = cv2.imread('image.jpg')
image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)

# ÿ™ÿ∑ÿ®ŸäŸÇ ÿ™ÿ≠ŸàŸäŸÑÿßÿ™ ŸáŸÜÿØÿ≥Ÿäÿ© ŸÖÿÆÿ™ŸÑŸÅÿ©
rotated = apply_geometric_transform(image_rgb, "Rotation", angle=45, scale=1.0)
scaled = apply_geometric_transform(image_rgb, "Scaling", scale_x=1.5, scale_y=1.5)
translated = apply_geometric_transform(image_rgb, "Translation", tx=100, ty=50)
flipped = apply_geometric_transform(image_rgb, "Flipping", flip_code=1)
cropped = apply_geometric_transform(image_rgb, "Cropping", x=100, y=100, width=200, height=200)

# ÿ™ÿ≠ŸàŸäŸÑÿßÿ™ ŸÖÿ™ŸÇÿØŸÖÿ©
affine = apply_geometric_transform(image_rgb, "Affine")
perspective = apply_geometric_transform(image_rgb, "Perspective")
'''
    display_code_editor(code, filename="geometric_transforms.py")

def main():
    # ÿ≠ŸÇŸÜ CSS ÿßŸÑŸÖÿÆÿµÿµ
    inject_custom_css()

    # ÿßŸÑÿ±ÿ£ÿ≥ ÿßŸÑÿ±ÿ¶Ÿäÿ≥Ÿä
    st.markdown("""
    <div class="custom-header">
        <h1>üé® ŸÖÿÆÿ™ÿ®ÿ± ŸÖÿπÿßŸÑÿ¨ÿ© ÿßŸÑÿµŸàÿ± ÿßŸÑŸÖÿ™ŸÇÿØŸÖ</h1>
        <h3>ŸÖÿ¥ÿ±Ÿàÿπ ŸÖÿ≠ÿßÿ∂ÿ±ÿßÿ™ ŸÖÿπÿßŸÑÿ¨ÿ© ÿßŸÑÿµŸàÿ± ÿßŸÑÿ±ŸÇŸÖŸäÿ©</h3>
    </div>
    """, unsafe_allow_html=True)

    # ÿ•ŸÜÿ¥ÿßÿ° ŸÇÿßÿ¶ŸÖÿ© ÿßŸÑŸÖÿ≠ÿßÿ∂ÿ±ÿßÿ™
    lectures = [
        "ÿßŸÑŸÖÿ≠ÿßÿ∂ÿ±ÿ© 1: ŸÖÿØÿÆŸÑ ŸàŸÖÿπÿßŸäÿ±ÿ© ÿßŸÑÿµŸàÿ±",
        "ÿßŸÑŸÖÿ≠ÿßÿ∂ÿ±ÿ© 2: ÿ£ŸÜÿ∏ŸÖÿ© ÿßŸÑÿ£ŸÑŸàÿßŸÜ",
        "ÿßŸÑŸÖÿ≠ÿßÿ∂ÿ±ÿ© 3: ÿ™ÿπÿØŸäŸÑ ÿßŸÑÿ≥ÿ∑Ÿàÿπ ŸàÿßŸÑÿ™ÿ®ÿßŸäŸÜ",
        "ÿßŸÑŸÖÿ≠ÿßÿ∂ÿ±ÿ© 4: ÿßŸÑŸÖÿ±ÿ¥ÿ≠ÿßÿ™ ŸàÿßŸÑÿßŸÑÿ™ŸÅÿßŸÅ",
        "ÿßŸÑŸÖÿ≠ÿßÿ∂ÿ±ÿ© 5: ÿ•ÿ≤ÿßŸÑÿ© ÿßŸÑÿ∂Ÿàÿ∂ÿßÿ°",
        "ÿßŸÑŸÖÿ≠ÿßÿ∂ÿ±ÿ© 6: ŸÉÿ¥ŸÅ ÿßŸÑÿ≠ŸàÿßŸÅ",
        "ÿßŸÑŸÖÿ≠ÿßÿ∂ÿ±ÿ© 7: ÿßŸÑÿπŸÖŸÑŸäÿßÿ™ ÿßŸÑŸÖŸàÿ±ŸÅŸàŸÑŸàÿ¨Ÿäÿ©",
        "ÿßŸÑŸÖÿ≠ÿßÿ∂ÿ±ÿ© 8: ÿßŸÑÿ™ÿ≠ŸàŸäŸÑÿßÿ™ ÿßŸÑŸáŸÜÿØÿ≥Ÿäÿ©",
        "ÿßŸÑŸÖÿ¥ÿ±Ÿàÿπ ÿßŸÑŸÜŸáÿßÿ¶Ÿä"
    ]

    # ÿ•ŸÜÿ¥ÿßÿ° ÿ™ÿ®ŸàŸäÿ®ÿßÿ™ ŸÑŸÑŸÖÿ≠ÿßÿ∂ÿ±ÿßÿ™
    tab1, tab2, tab3, tab4, tab5, tab6, tab7, tab8, tab9 = st.tabs(lectures)

    with tab1:
        st.markdown("## ÿßŸÑŸÖÿ≠ÿßÿ∂ÿ±ÿ© 1: ŸÖÿØÿÆŸÑ ŸàŸÖÿπÿßŸäÿ±ÿ© ÿßŸÑÿµŸàÿ± ÿßŸÑÿ±ŸÇŸÖŸäÿ©")
        lecture_1()
        
        # ÿßŸÑÿ™ÿ∑ÿ®ŸäŸÇ ÿßŸÑÿπŸÖŸÑŸä ŸÑŸÑŸÖÿ≠ÿßÿ∂ÿ±ÿ© 1
        st.markdown("### üß™ ÿßŸÑÿ™ÿ¨ÿ±ÿ®ÿ© ÿßŸÑÿπŸÖŸÑŸäÿ©")
        uploaded_file = st.file_uploader("ÿßÿÆÿ™ÿ± ÿµŸàÿ±ÿ© ŸÑŸÖÿπÿßŸÑÿ¨ÿ™Ÿáÿß", type=["jpg", "jpeg", "png"], key="lecture1")
        
        if uploaded_file is not None:
            file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
            image = cv2.imdecode(file_bytes, 1)
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            
            col1, col2 = st.columns(2)
            with col1:
                st.image(image, caption="üñºÔ∏è ÿßŸÑÿµŸàÿ±ÿ© ÿßŸÑÿ£ÿµŸÑŸäÿ©", use_container_width=True)
            
            with col2:
                st.info(f"**ŸÖÿπŸÑŸàŸÖÿßÿ™ ÿßŸÑÿµŸàÿ±ÿ©:**")
                st.write(f"**ÿßŸÑÿ£ÿ®ÿπÿßÿØ:** {image.shape[1]} x {image.shape[0]}")
                st.write(f"**ÿπÿØÿØ ÿßŸÑŸÇŸÜŸàÿßÿ™:** {image.shape[2]}")
                st.write(f"**ŸÜŸàÿπ ÿßŸÑÿ®ŸäÿßŸÜÿßÿ™:** {image.dtype}")
                st.write(f"**ŸÖÿØŸâ ÿßŸÑŸÇŸäŸÖ:** {np.min(image)} ÿ•ŸÑŸâ {np.max(image)}")

    with tab2:
        st.markdown("## ÿßŸÑŸÖÿ≠ÿßÿ∂ÿ±ÿ© 2: ÿ£ŸÜÿ∏ŸÖÿ© ÿßŸÑÿ£ŸÑŸàÿßŸÜ (Color Spaces)")
        lecture_2()
        
        # ÿßŸÑÿ™ÿ∑ÿ®ŸäŸÇ ÿßŸÑÿπŸÖŸÑŸä ŸÑŸÑŸÖÿ≠ÿßÿ∂ÿ±ÿ© 2
        st.markdown("### üß™ ÿßŸÑÿ™ÿ¨ÿ±ÿ®ÿ© ÿßŸÑÿπŸÖŸÑŸäÿ©")
        uploaded_file = st.file_uploader("ÿßÿÆÿ™ÿ± ÿµŸàÿ±ÿ© ŸÑŸÖÿπÿßŸÑÿ¨ÿ™Ÿáÿß", type=["jpg", "jpeg", "png"], key="lecture2")
        
        if uploaded_file is not None:
            file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
            image = cv2.imdecode(file_bytes, 1)
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            
            color_space = st.selectbox("ÿßÿÆÿ™ÿ± ŸÜÿ∏ÿßŸÖ ÿßŸÑÿ£ŸÑŸàÿßŸÜ ŸÑŸÑÿ™ÿ≠ŸàŸäŸÑ:", 
                                     ["RGB", "GRAY", "HSV", "LAB", "YUV"])
            
            if color_space == "GRAY":
                converted = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)
                converted = cv2.cvtColor(converted, cv2.COLOR_GRAY2RGB)
            elif color_space == "HSV":
                converted = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)
            elif color_space == "LAB":
                converted = cv2.cvtColor(image, cv2.COLOR_RGB2LAB)
            elif color_space == "YUV":
                converted = cv2.cvtColor(image, cv2.COLOR_RGB2YUV)
            else:
                converted = image
            
            col1, col2 = st.columns(2)
            with col1:
                st.image(image, caption="üñºÔ∏è ÿßŸÑÿµŸàÿ±ÿ© ÿßŸÑÿ£ÿµŸÑŸäÿ© (RGB)", use_container_width=True)
            with col2:
                st.image(converted, caption=f"üîÑ ÿßŸÑÿµŸàÿ±ÿ© ÿßŸÑŸÖÿ≠ŸàŸÑÿ© ({color_space})", use_container_width=True)

    with tab3:
        st.markdown("## ÿßŸÑŸÖÿ≠ÿßÿ∂ÿ±ÿ© 3: ÿ™ÿπÿØŸäŸÑ ÿßŸÑÿ≥ÿ∑Ÿàÿπ ŸàÿßŸÑÿ™ÿ®ÿßŸäŸÜ")
        lecture_3()
        
        # ÿßŸÑÿ™ÿ∑ÿ®ŸäŸÇ ÿßŸÑÿπŸÖŸÑŸä ŸÑŸÑŸÖÿ≠ÿßÿ∂ÿ±ÿ© 3
        st.markdown("### üß™ ÿßŸÑÿ™ÿ¨ÿ±ÿ®ÿ© ÿßŸÑÿπŸÖŸÑŸäÿ©")
        uploaded_file = st.file_uploader("ÿßÿÆÿ™ÿ± ÿµŸàÿ±ÿ© ŸÑŸÖÿπÿßŸÑÿ¨ÿ™Ÿáÿß", type=["jpg", "jpeg", "png"], key="lecture3")
        
        if uploaded_file is not None:
            file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
            image = cv2.imdecode(file_bytes, 1)
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            
            col1, col2 = st.columns(2)
            with col1:
                st.image(image, caption="üñºÔ∏è ÿßŸÑÿµŸàÿ±ÿ© ÿßŸÑÿ£ÿµŸÑŸäÿ©", use_container_width=True)
            
            with col2:
                brightness = st.slider("üîÜ ÿßŸÑÿ≥ÿ∑Ÿàÿπ", -100, 100, 0, key="brightness_slider")
                contrast = st.slider("üåà ÿßŸÑÿ™ÿ®ÿßŸäŸÜ", 0, 200, 100, key="contrast_slider")
                threshold = st.slider("‚ö´Ô∏è ÿßŸÑÿπÿ™ÿ®ÿ©", 0, 255, 127, key="threshold_slider")
                
                if st.button("üöÄ ÿ™ÿ∑ÿ®ŸäŸÇ ÿßŸÑÿ™ÿπÿØŸäŸÑÿßÿ™", key="apply_btn"):
                    adjusted = adjust_brightness_contrast(image, brightness, contrast)
                    thresholded = apply_threshold(image, "THRESH_BINARY", threshold)
                    negative = 255 - image
                    
                    tab_a, tab_b, tab_c = st.tabs(["ÿßŸÑÿ≥ÿ∑Ÿàÿπ ŸàÿßŸÑÿ™ÿ®ÿßŸäŸÜ", "ÿßŸÑÿπÿ™ÿ®ÿ©", "ÿßŸÑÿµŸàÿ±ÿ© ÿßŸÑÿ≥ÿßŸÑÿ®ÿ©"])
                    
                    with tab_a:
                        st.image(adjusted, caption="üîÑ ÿßŸÑÿ≥ÿ∑Ÿàÿπ ŸàÿßŸÑÿ™ÿ®ÿßŸäŸÜ", use_container_width=True)
                    with tab_b:
                        st.image(thresholded, caption="‚ö´Ô∏è ÿßŸÑÿπÿ™ÿ®ÿ©", use_container_width=True)
                    with tab_c:
                        st.image(negative, caption="üåó ÿßŸÑÿµŸàÿ±ÿ© ÿßŸÑÿ≥ÿßŸÑÿ®ÿ©", use_container_width=True)

    with tab4:
        st.markdown("## ÿßŸÑŸÖÿ≠ÿßÿ∂ÿ±ÿ© 4: ÿßŸÑŸÖÿ±ÿ¥ÿ≠ÿßÿ™ ŸàÿßŸÑÿßŸÑÿ™ŸÅÿßŸÅ")
        lecture_4()
        
        # ÿßŸÑÿ™ÿ∑ÿ®ŸäŸÇ ÿßŸÑÿπŸÖŸÑŸä ŸÑŸÑŸÖÿ≠ÿßÿ∂ÿ±ÿ© 4
        st.markdown("### üß™ ÿßŸÑÿ™ÿ¨ÿ±ÿ®ÿ© ÿßŸÑÿπŸÖŸÑŸäÿ©")
        uploaded_file = st.file_uploader("ÿßÿÆÿ™ÿ± ÿµŸàÿ±ÿ© ŸÑŸÖÿπÿßŸÑÿ¨ÿ™Ÿáÿß", type=["jpg", "jpeg", "png"], key="lecture4")
        
        if uploaded_file is not None:
            file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
            image = cv2.imdecode(file_bytes, 1)
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            
            filter_type = st.selectbox("ÿßÿÆÿ™ÿ± ŸÜŸàÿπ ÿßŸÑŸÖÿ±ÿ¥ÿ≠:", 
                                     ["Blur", "Gaussian Blur", "Median Blur", "Sharpen", "Emboss", "Edge Detection"])
            
            kernel_size = st.slider("ÿ≠ÿ¨ŸÖ ÿßŸÑŸÜŸàÿßÿ©", 3, 15, 5, 2, key="kernel_size")
            
            if st.button("üöÄ ÿ™ÿ∑ÿ®ŸäŸÇ ÿßŸÑŸÖÿ±ÿ¥ÿ≠", key="apply_filter_btn"):
                filtered = apply_filter(image, filter_type, kernel_size)
                
                col1, col2 = st.columns(2)
                with col1:
                    st.image(image, caption="üñºÔ∏è ÿßŸÑÿµŸàÿ±ÿ© ÿßŸÑÿ£ÿµŸÑŸäÿ©", use_container_width=True)
                with col2:
                    st.image(filtered, caption=f"‚ú® ÿßŸÑÿµŸàÿ±ÿ© ÿ®ÿπÿØ {filter_type}", use_container_width=True)

    with tab5:
        st.markdown("## ÿßŸÑŸÖÿ≠ÿßÿ∂ÿ±ÿ© 5: ÿ•ÿ≤ÿßŸÑÿ© ÿßŸÑÿ∂Ÿàÿ∂ÿßÿ°")
        lecture_5()
        
        # ÿßŸÑÿ™ÿ∑ÿ®ŸäŸÇ ÿßŸÑÿπŸÖŸÑŸä ŸÑŸÑŸÖÿ≠ÿßÿ∂ÿ±ÿ© 5
        st.markdown("### üß™ ÿßŸÑÿ™ÿ¨ÿ±ÿ®ÿ© ÿßŸÑÿπŸÖŸÑŸäÿ©")
        uploaded_file = st.file_uploader("ÿßÿÆÿ™ÿ± ÿµŸàÿ±ÿ© ŸÑŸÖÿπÿßŸÑÿ¨ÿ™Ÿáÿß", type=["jpg", "jpeg", "png"], key="lecture5")
        
        if uploaded_file is not None:
            file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
            image = cv2.imdecode(file_bytes, 1)
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            
            noise_type = st.selectbox("ÿßÿÆÿ™ÿ± ŸÜŸàÿπ ÿßŸÑÿ∂Ÿàÿ∂ÿßÿ°:", ["Gaussian", "Salt & Pepper"])
            denoise_type = st.selectbox("ÿßÿÆÿ™ÿ± ÿ∑ÿ±ŸäŸÇÿ© ÿ•ÿ≤ÿßŸÑÿ© ÿßŸÑÿ∂Ÿàÿ∂ÿßÿ°:", ["Median", "Gaussian", "Bilateral"])
            
            if st.button("üöÄ ÿ™ÿ∑ÿ®ŸäŸÇ ÿßŸÑŸÖÿπÿßŸÑÿ¨ÿ©", key="apply_denoise_btn"):
                # ÿ•ÿ∂ÿßŸÅÿ© ÿßŸÑÿ∂Ÿàÿ∂ÿßÿ°
                noisy = add_noise(image, noise_type)
                
                # ÿ•ÿ≤ÿßŸÑÿ© ÿßŸÑÿ∂Ÿàÿ∂ÿßÿ°
                denoised = remove_noise(noisy, denoise_type)
                
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.image(image, caption="üñºÔ∏è ÿßŸÑÿµŸàÿ±ÿ© ÿßŸÑÿ£ÿµŸÑŸäÿ©", use_container_width=True)
                with col2:
                    st.image(noisy, caption=f"üîä ÿßŸÑÿµŸàÿ±ÿ© ŸÖÿπ {noise_type} noise", use_container_width=True)
                with col3:
                    st.image(denoised, caption=f"üîá ÿßŸÑÿµŸàÿ±ÿ© ÿ®ÿπÿØ {denoise_type} filter", use_container_width=True)

    with tab6:
        st.markdown("## ÿßŸÑŸÖÿ≠ÿßÿ∂ÿ±ÿ© 6: ŸÉÿ¥ŸÅ ÿßŸÑÿ≠ŸàÿßŸÅ")
        lecture_6()
        
        # ÿßŸÑÿ™ÿ∑ÿ®ŸäŸÇ ÿßŸÑÿπŸÖŸÑŸä ŸÑŸÑŸÖÿ≠ÿßÿ∂ÿ±ÿ© 6
        st.markdown("### üß™ ÿßŸÑÿ™ÿ¨ÿ±ÿ®ÿ© ÿßŸÑÿπŸÖŸÑŸäÿ©")
        uploaded_file = st.file_uploader("ÿßÿÆÿ™ÿ± ÿµŸàÿ±ÿ© ŸÑŸÖÿπÿßŸÑÿ¨ÿ™Ÿáÿß", type=["jpg", "jpeg", "png"], key="lecture6")
        
        if uploaded_file is not None:
            file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
            image = cv2.imdecode(file_bytes, 1)
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            
            edge_method = st.selectbox("ÿßÿÆÿ™ÿ± ÿ∑ÿ±ŸäŸÇÿ© ŸÉÿ¥ŸÅ ÿßŸÑÿ≠ŸàÿßŸÅ:", ["Canny", "Sobel", "Laplacian", "Prewitt"])
            
            if edge_method == "Canny":
                threshold1 = st.slider("ÿßŸÑÿπÿ™ÿ®ÿ© ÿßŸÑÿØŸÜŸäÿß", 0, 255, 100, key="threshold1")
                threshold2 = st.slider("ÿßŸÑÿπÿ™ÿ®ÿ© ÿßŸÑÿπŸÑŸäÿß", 0, 255, 200, key="threshold2")
            else:
                threshold1, threshold2 = 100, 200
            
            if st.button("üöÄ ŸÉÿ¥ŸÅ ÿßŸÑÿ≠ŸàÿßŸÅ", key="detect_edges_btn"):
                edges = detect_edges(image, edge_method, threshold1, threshold2)
                
                col1, col2 = st.columns(2)
                with col1:
                    st.image(image, caption="üñºÔ∏è ÿßŸÑÿµŸàÿ±ÿ© ÿßŸÑÿ£ÿµŸÑŸäÿ©", use_container_width=True)
                with col2:
                    st.image(edges, caption=f"üîç ÿßŸÑÿ≠ŸàÿßŸÅ ÿ®ŸÄ {edge_method}", use_container_width=True)

    with tab7:
        st.markdown("## ÿßŸÑŸÖÿ≠ÿßÿ∂ÿ±ÿ© 7: ÿßŸÑÿπŸÖŸÑŸäÿßÿ™ ÿßŸÑŸÖŸàÿ±ŸÅŸàŸÑŸàÿ¨Ÿäÿ©")
        lecture_7()
        
        # ÿßŸÑÿ™ÿ∑ÿ®ŸäŸÇ ÿßŸÑÿπŸÖŸÑŸä ŸÑŸÑŸÖÿ≠ÿßÿ∂ÿ±ÿ© 7
        st.markdown("### üß™ ÿßŸÑÿ™ÿ¨ÿ±ÿ®ÿ© ÿßŸÑÿπŸÖŸÑŸäÿ©")
        uploaded_file = st.file_uploader("ÿßÿÆÿ™ÿ± ÿµŸàÿ±ÿ© ŸÑŸÖÿπÿßŸÑÿ¨ÿ™Ÿáÿß", type=["jpg", "jpeg", "png"], key="lecture7")
        
        if uploaded_file is not None:
            file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
            image = cv2.imdecode(file_bytes, 1)
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            
            morph_operation = st.selectbox("ÿßÿÆÿ™ÿ± ÿßŸÑÿπŸÖŸÑŸäÿ© ÿßŸÑŸÖŸàÿ±ŸÅŸàŸÑŸàÿ¨Ÿäÿ©:", 
                                         ["Erosion", "Dilation", "Opening", "Closing", "Gradient"])
            
            kernel_size = st.slider("ÿ≠ÿ¨ŸÖ ÿßŸÑŸÜŸàÿßÿ©", 3, 15, 5, 2, key="morph_kernel_size")
            iterations = st.slider("ÿπÿØÿØ ÿßŸÑÿ™ŸÉÿ±ÿßÿ±ÿßÿ™", 1, 10, 1, key="morph_iterations")
            
            if st.button("üöÄ ÿ™ÿ∑ÿ®ŸäŸÇ ÿßŸÑÿπŸÖŸÑŸäÿ©", key="apply_morph_btn"):
                result = apply_morphological_operation(image, morph_operation, kernel_size, iterations)
                
                col1, col2 = st.columns(2)
                with col1:
                    st.image(image, caption="üñºÔ∏è ÿßŸÑÿµŸàÿ±ÿ© ÿßŸÑÿ£ÿµŸÑŸäÿ©", use_container_width=True)
                with col2:
                    st.image(result, caption=f"‚ú® ÿ®ÿπÿØ {morph_operation}", use_container_width=True)

    with tab8:
        st.markdown("## ÿßŸÑŸÖÿ≠ÿßÿ∂ÿ±ÿ© 8: ÿßŸÑÿ™ÿ≠ŸàŸäŸÑÿßÿ™ ÿßŸÑŸáŸÜÿØÿ≥Ÿäÿ©")
        lecture_8()
        
        # ÿßŸÑÿ™ÿ∑ÿ®ŸäŸÇ ÿßŸÑÿπŸÖŸÑŸä ŸÑŸÑŸÖÿ≠ÿßÿ∂ÿ±ÿ© 8
        st.markdown("### üß™ ÿßŸÑÿ™ÿ¨ÿ±ÿ®ÿ© ÿßŸÑÿπŸÖŸÑŸäÿ©")
        uploaded_file = st.file_uploader("ÿßÿÆÿ™ÿ± ÿµŸàÿ±ÿ© ŸÑŸÖÿπÿßŸÑÿ¨ÿ™Ÿáÿß", type=["jpg", "jpeg", "png"], key="lecture8")
        
        if uploaded_file is not None:
            file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
            image = cv2.imdecode(file_bytes, 1)
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            
            transform_type = st.selectbox("ÿßÿÆÿ™ÿ± ŸÜŸàÿπ ÿßŸÑÿ™ÿ≠ŸàŸäŸÑ:", 
                                        ["Rotation", "Scaling", "Translation", "Flipping", "Cropping"])
            
            if transform_type == "Rotation":
                angle = st.slider("ÿ≤ÿßŸàŸäÿ© ÿßŸÑÿØŸàÿ±ÿßŸÜ", -180, 180, 45, key="rotation_angle")
                scale = st.slider("ŸÖŸÇŸäÿßÿ≥ ÿßŸÑÿ™ŸÉÿ®Ÿäÿ±", 0.1, 3.0, 1.0, 0.1, key="rotation_scale")
                result = apply_geometric_transform(image, transform_type, angle=angle, scale=scale)
                
            elif transform_type == "Scaling":
                scale_x = st.slider("ŸÖŸÇŸäÿßÿ≥ ÿßŸÑÿ™ŸÉÿ®Ÿäÿ± ÿßŸÑÿ£ŸÅŸÇŸä", 0.1, 3.0, 1.5, 0.1, key="scale_x")
                scale_y = st.slider("ŸÖŸÇŸäÿßÿ≥ ÿßŸÑÿ™ŸÉÿ®Ÿäÿ± ÿßŸÑÿπŸÖŸàÿØŸä", 0.1, 3.0, 1.5, 0.1, key="scale_y")
                result = apply_geometric_transform(image, transform_type, scale_x=scale_x, scale_y=scale_y)
                
            elif transform_type == "Translation":
                tx = st.slider("ÿßŸÑÿ•ÿ≤ÿßÿ≠ÿ© ÿßŸÑÿ£ŸÅŸÇŸäÿ©", -200, 200, 100, key="translation_x")
                ty = st.slider("ÿßŸÑÿ•ÿ≤ÿßÿ≠ÿ© ÿßŸÑÿπŸÖŸàÿØŸäÿ©", -200, 200, 50, key="translation_y")
                result = apply_geometric_transform(image, transform_type, tx=tx, ty=ty)
                
            elif transform_type == "Flipping":
                flip_code = st.selectbox("ÿßÿÆÿ™ÿ± ÿßÿ™ÿ¨ÿßŸá ÿßŸÑÿßŸÜÿπŸÉÿßÿ≥:", 
                                       [("ÿßŸÅŸÇŸä", 1), ("ÿπŸÖŸàÿØŸä", 0), ("ŸÉŸÑÿßŸáŸÖÿß", -1)], 
                                       format_func=lambda x: x[0])
                result = apply_geometric_transform(image, transform_type, flip_code=flip_code[1])
                
            elif transform_type == "Cropping":
                x = st.slider("ÿßŸÑŸÜŸÇÿ∑ÿ© X", 0, image.shape[1]-100, 100, key="crop_x")
                y = st.slider("ÿßŸÑŸÜŸÇÿ∑ÿ© Y", 0, image.shape[0]-100, 100, key="crop_y")
                width = st.slider("ÿßŸÑÿπÿ±ÿ∂", 100, image.shape[1]-x, 200, key="crop_width")
                height = st.slider("ÿßŸÑÿßÿ±ÿ™ŸÅÿßÿπ", 100, image.shape[0]-y, 200, key="crop_height")
                result = apply_geometric_transform(image, transform_type, x=x, y=y, width=width, height=height)
            
            if st.button("üöÄ ÿ™ÿ∑ÿ®ŸäŸÇ ÿßŸÑÿ™ÿ≠ŸàŸäŸÑ", key="apply_transform_btn"):
                col1, col2 = st.columns(2)
                with col1:
                    st.image(image, caption="üñºÔ∏è ÿßŸÑÿµŸàÿ±ÿ© ÿßŸÑÿ£ÿµŸÑŸäÿ©", use_container_width=True)
                with col2:
                    st.image(result, caption=f"‚ú® ÿ®ÿπÿØ {transform_type}", use_container_width=True)

    with tab9:
        st.markdown("## ÿßŸÑŸÖÿ¥ÿ±Ÿàÿπ ÿßŸÑŸÜŸáÿßÿ¶Ÿä: pipeline ŸÖÿπÿßŸÑÿ¨ÿ© ÿßŸÑÿµŸàÿ±")
        st.markdown("### üß™ ÿ£ŸÜÿ¥ÿ¶ pipeline ŸÖÿπÿßŸÑÿ¨ÿ© ÿßŸÑÿµŸàÿ± ÿßŸÑÿÆÿßÿµ ÿ®ŸÉ")
        
        uploaded_file = st.file_uploader("ÿßÿÆÿ™ÿ± ÿµŸàÿ±ÿ© ŸÑŸÖÿπÿßŸÑÿ¨ÿ™Ÿáÿß", type=["jpg", "jpeg", "png"], key="final_project")
        
        if uploaded_file is not None:
            file_bytes = np.asarray(bytearray(uploaded_file.read()), dtype=np.uint8)
            image = cv2.imdecode(file_bytes, 1)
            image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
            
            st.image(image, caption="üñºÔ∏è ÿßŸÑÿµŸàÿ±ÿ© ÿßŸÑÿ£ÿµŸÑŸäÿ©", use_container_width=True)
            
            # ÿ•ÿπÿØÿßÿØ pipeline ÿßŸÑŸÖÿπÿßŸÑÿ¨ÿ©
            st.markdown("### ‚öôÔ∏è ÿÆÿ∑Ÿàÿßÿ™ ÿßŸÑŸÖÿπÿßŸÑÿ¨ÿ©:")
            steps = st.multiselect(
                "ÿßÿÆÿ™ÿ± ÿÆÿ∑Ÿàÿßÿ™ ÿßŸÑŸÖÿπÿßŸÑÿ¨ÿ©:",
                ["ÿ™ÿ≠ŸàŸäŸÑ ÿ•ŸÑŸâ ÿ±ŸÖÿßÿØŸä", "ÿ∂ÿ®ÿ∑ ÿßŸÑÿ≥ÿ∑Ÿàÿπ ŸàÿßŸÑÿ™ÿ®ÿßŸäŸÜ", "ÿ™ÿ∑ÿ®ŸäŸÇ ŸÖÿ±ÿ¥ÿ≠", "ŸÉÿ¥ŸÅ ÿßŸÑÿ≠ŸàÿßŸÅ", "ÿπÿ™ÿ®ÿ©", "ÿπŸÖŸÑŸäÿßÿ™ ŸÖŸàÿ±ŸÅŸàŸÑŸàÿ¨Ÿäÿ©"],
                default=["ÿ™ÿ≠ŸàŸäŸÑ ÿ•ŸÑŸâ ÿ±ŸÖÿßÿØŸä", "ŸÉÿ¥ŸÅ ÿßŸÑÿ≠ŸàÿßŸÅ"]
            )
            
            processed_image = image.copy()
            process_history = []
            
            for step in steps:
                if step == "ÿ™ÿ≠ŸàŸäŸÑ ÿ•ŸÑŸâ ÿ±ŸÖÿßÿØŸä":
                    processed_image = cv2.cvtColor(processed_image, cv2.COLOR_RGB2GRAY)
                    processed_image = cv2.cvtColor(processed_image, cv2.COLOR_GRAY2RGB)
                    process_history.append("ÿ™ÿ≠ŸàŸäŸÑ ÿ•ŸÑŸâ ÿ™ÿØÿ±ÿ¨ ÿßŸÑÿ±ŸÖÿßÿØŸä")
                
                elif step == "ÿ∂ÿ®ÿ∑ ÿßŸÑÿ≥ÿ∑Ÿàÿπ ŸàÿßŸÑÿ™ÿ®ÿßŸäŸÜ":
                    processed_image = adjust_brightness_contrast(processed_image, 20, 120)
                    process_history.append("ÿ∂ÿ®ÿ∑ ÿßŸÑÿ≥ÿ∑Ÿàÿπ (+20) ŸàÿßŸÑÿ™ÿ®ÿßŸäŸÜ (+20%)")
                
                elif step == "ÿ™ÿ∑ÿ®ŸäŸÇ ŸÖÿ±ÿ¥ÿ≠":
                    processed_image = apply_filter(processed_image, "Gaussian Blur", 5)
                    process_history.append("ÿ™ÿ∑ÿ®ŸäŸÇ ŸÖÿ±ÿ¥ÿ≠ Gaussian Blur (5x5)")
                
                elif step == "ŸÉÿ¥ŸÅ ÿßŸÑÿ≠ŸàÿßŸÅ":
                    processed_image = detect_edges(processed_image, "Canny", 100, 200)
                    process_history.append("ŸÉÿ¥ŸÅ ÿßŸÑÿ≠ŸàÿßŸÅ ÿ®ŸÄ Canny")
                
                elif step == "ÿπÿ™ÿ®ÿ©":
                    processed_image = apply_threshold(processed_image, "THRESH_BINARY", 127)
                    process_history.append("ÿ™ÿ∑ÿ®ŸäŸÇ ÿßŸÑÿπÿ™ÿ®ÿ© ÿßŸÑÿ´ŸÜÿßÿ¶Ÿäÿ© (127)")
                
                elif step == "ÿπŸÖŸÑŸäÿßÿ™ ŸÖŸàÿ±ŸÅŸàŸÑŸàÿ¨Ÿäÿ©":
                    processed_image = apply_morphological_operation(processed_image, "Closing", 3)
                    process_history.append("ÿπŸÖŸÑŸäÿ© Closing ŸÖŸàÿ±ŸÅŸàŸÑŸàÿ¨Ÿäÿ© (3x3)")
            
            if st.button("‚ñ∂Ô∏è ÿ™ÿ¥ÿ∫ŸäŸÑ Pipeline", key="run_pipeline"):
                st.markdown("### üìä ŸÜÿ™ÿßÿ¶ÿ¨ ÿßŸÑŸÖÿπÿßŸÑÿ¨ÿ©:")
                
                col1, col2 = st.columns(2)
                with col1:
                    st.image(image, caption="üñºÔ∏è ÿßŸÑÿµŸàÿ±ÿ© ÿßŸÑÿ£ÿµŸÑŸäÿ©", use_container_width=True)
                with col2:
                    st.image(processed_image, caption="‚ú® ÿßŸÑÿµŸàÿ±ÿ© ÿßŸÑŸÜŸáÿßÿ¶Ÿäÿ©", use_container_width=True)
                
                st.markdown("### üìù ÿ≥ÿ¨ŸÑ ÿßŸÑŸÖÿπÿßŸÑÿ¨ÿ©:")
                for i, step in enumerate(process_history, 1):
                    st.write(f"{i}. {step}")
                
                # ÿ•ŸÖŸÉÿßŸÜŸäÿ© ÿ≠ŸÅÿ∏ ÿßŸÑÿµŸàÿ±ÿ© ÿßŸÑŸÜÿßÿ™ÿ¨ÿ©
                buf = io.BytesIO()
                processed_pil = Image.fromarray(processed_image)
                processed_pil.save(buf, format="JPEG", quality=95)
                byte_im = buf.getvalue()
                
                st.download_button(
                    label="üíæ ÿ™ÿ≠ŸÖŸäŸÑ ÿßŸÑÿµŸàÿ±ÿ© ÿßŸÑŸÜŸáÿßÿ¶Ÿäÿ©",
                    data=byte_im,
                    file_name="processed_image.jpg",
                    mime="image/jpeg",
                    use_container_width=True
                )

    # ÿßŸÑÿ™ÿ∞ŸäŸäŸÑ
    st.markdown("""
    <footer>
        <p>ÿ™ŸÖ ÿßŸÑÿ™ÿµŸÖŸäŸÖ ŸàÿßŸÑÿ™ÿ∑ŸàŸäÿ± ÿ®Ÿàÿßÿ≥ÿ∑ÿ© ÿßŸÑŸÖŸáŸÜÿØÿ≥ ÿ≤ŸÉÿ±Ÿäÿß ŸÇÿßÿ±Ÿäÿ©</p>
        <p>ŸÖÿ¥ÿ±Ÿàÿπ ŸÖÿπÿßŸÑÿ¨ÿ© ÿßŸÑÿµŸàÿ± ÿßŸÑÿ±ŸÇŸÖŸäÿ© - ŸÉŸÑŸäÿ© ÿßŸÑŸáŸÜÿØÿ≥ÿ© ¬© 2023</p>
    </footer>
    """, unsafe_allow_html=True)

if __name__ == "__main__":
    main()